{"cells":[{"cell_type":"markdown","metadata":{"id":"9af74Nwj3BIy"},"source":["# IMD3004 - IA Generativa"]},{"cell_type":"markdown","metadata":{"id":"_pwt8WA-3EGx"},"source":["### Professor: Dr. Leonardo Enzo Brito da Silva"]},{"cell_type":"markdown","metadata":{"id":"ZrrRZuYa3FxY"},"source":["### Aluno: João Antonio Costa Paiva Chagas"]},{"cell_type":"markdown","source":["# Laboratório 8: Autoencoders"],"metadata":{"id":"pu7DXYieUU4Y"}},{"cell_type":"markdown","metadata":{"id":"KcaYyev3s78j"},"source":["Código adaptado de:\n","\n","[1] Aurélien Géron, Hands-On Machine Learning with Scikit-Learn: Concepts, Tools and Techniques to Build Intelligent Systems, Keras & tensorFlow, Third Edition, O'Reilly, 2023."]},{"cell_type":"markdown","source":["## Importações e Ambiente"],"metadata":{"id":"qTPJYxIkLaug"}},{"cell_type":"code","source":["! pip install torchinfo"],"metadata":{"id":"nPRVExhCLiWN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import sys                                                  # importa acesso a informações do sistema\n","import os                                                   # importa utilidades de sistema de arquivos\n","import io                                                   # Para salvar o sumário...\n","import numpy as np                                          # importa Numpy\n","import torch                                                # importa PyTorch\n","import torch.nn as nn                                       # importa módulos de redes neurais\n","import torch.optim as optim                                 # importa otimizadores\n","from torch.utils.data import DataLoader, TensorDataset      # importa utilitários de dados\n","from torchvision import datasets                            # importa datasets\n","from torchinfo import summary                               # importa função para exibir resumo das arquiteturas de rede\n","import matplotlib.pyplot as plt                             # importa biblioteca de gráficos\n","import matplotlib as mpl                                    # importa configurações avançadas de gráficos Matplotlib\n","from scipy.spatial.transform import Rotation                # importa rotação 3D para gerar dados sintéticos\n","from tqdm.auto import tqdm                                  # importa tqdm adaptável (funciona em terminal e notebook)\n","from typing import Optional                                 # Para salvar os plots...\n","\n","torch.manual_seed(42)                                       # fixa semente do PyTorch para reprodutibilidade\n","np.random.seed(42)                                          # fixa semente do NumPy para reprodutibilidade\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # escolhe GPU se disponível"],"metadata":{"id":"DJCvVh8sLglq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Armazenamento"],"metadata":{"id":"vP3rRxgsWJkP"}},{"cell_type":"code","source":["output_dir = \"resultados_plots\"\n","os.makedirs(output_dir, exist_ok=True)"],"metadata":{"id":"t4wl0ibCWLIV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Hiperparâmetros"],"metadata":{"id":"Z3B396rRMzhZ"}},{"cell_type":"code","source":["Z_DIM = 2\n","Z_DIM_DENOISING_AE = 30\n","Z_DIM_SPARSE_AE = 300\n","N_EPOCHS = 100"],"metadata":{"id":"cZ-2SnzXM1BO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dados"],"metadata":{"id":"wAVNhIcCN6Bb"}},{"cell_type":"code","source":["# Carregar MNIST\n","train_full  = datasets.MNIST(root=\"data\", train=True, download=True)            # carrega conjunto de treinamento\n","test_ds     = datasets.MNIST(root=\"data\", train=False, download=True)           # carrega conjunto de teste\n","X_full = train_full.data.float() / 255.0                                        # normaliza imagens de treinamento\n","y_full = train_full.targets.long()                                              # rótulos de treinamento\n","X_test = test_ds.data.float() / 255.0                                           # normaliza imagens de teste\n","y_test = test_ds.targets.long()                                                 # rótulos de teste\n","\n","X_train = X_full[:-5000]  # fatia X treinamento\n","y_train = y_full[:-5000]  # fatia y rótulos\n","X_valid = X_full[-5000:]  # fatia X validação\n","y_valid = y_full[-5000:]  # fatia y rótulos\n","\n","X_train = X_train.unsqueeze(1)      # adiciona canal para shape [batch, channels, height, width] (ou (B, C, H, W))\n","X_valid = X_valid.unsqueeze(1)      # adiciona canal para shape [batch, channels, height, width] (ou (B, C, H, W))\n","X_test  = X_test.unsqueeze(1)       # adiciona canal para shape [batch, channels, height, width] (ou (B, C, H, W))\n","\n","train_ds = TensorDataset(X_train, X_train)                      # conjunto de treinamento\n","valid_ds = TensorDataset(X_valid, X_valid)                      # conjunto de validação\n","train_dl = DataLoader(train_ds, batch_size=128, shuffle=True)   # dataloader de treinamento\n","valid_dl = DataLoader(valid_ds, batch_size=256, shuffle=False)  # dataloader de validação"],"metadata":{"id":"SMt8HX6RN615"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Autoencoders"],"metadata":{"id":"qCctgA4rOt8a"}},{"cell_type":"markdown","source":["### Convolucional"],"metadata":{"id":"sMXXQIkCOvWS"}},{"cell_type":"code","source":["# codificador convolucional\n","class ConvEncoder(nn.Module):\n","    def __init__(self):                                 # construtor\n","        super().__init__()                              # base\n","        self.net = nn.Sequential(                       # sequência de camadas\n","            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2),\n","            nn.Conv2d(64, Z_DIM, kernel_size=3, padding=1),\n","            nn.AdaptiveAvgPool2d((1, 1)),               # global average pooling\n","        )\n","    def forward(self, x):           # forward\n","        x = self.net(x)             # aplica camadas\n","        z = x.view(x.size(0), -1)\n","        return z                    # retorna código\n","\n","# decodificador convolucional\n","class ConvDecoder(nn.Module):\n","    def __init__(self):                             # construtor\n","        super().__init__()                          # base\n","        self.fc = nn.Linear(Z_DIM, 3 * 3 * 16)\n","        self.net = nn.Sequential(                   # sequência de camadas\n","            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=2),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n","        )\n","    def forward(self, z):           # forward\n","        x = self.fc(z)              # projeta para mapa baixo\n","        x = x.view(-1, 16, 3, 3)\n","        x = self.net(x)             # aplica deconvs\n","        x = x.squeeze(1)            # remove canal para (N,28,28)\n","        return x                    # retorna reconstrução\n","\n","# AE convolucional\n","class ConvAE(nn.Module):\n","    def __init__(self):                 # construtor\n","        super().__init__()              # base\n","        self.encoder = ConvEncoder()    # instancia encoder\n","        self.decoder = ConvDecoder()    # instancia decoder\n","    def forward(self, x):               # forward\n","        z = self.encoder(x)             # codifica\n","        x_hat = self.decoder(z)         # decodifica\n","        return x_hat, z                 # retorna reconstrução e código\n","\n","conv_ae = ConvAE().to(device)  # instancia ConvAE"],"metadata":{"id":"bi3sxinPO1tO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Esparso"],"metadata":{"id":"2oB0yWW2OyWq"}},{"cell_type":"code","source":["# Encoder esparso\n","class SparseEncoder(nn.Module):\n","    def __init__(self):             # construtor\n","        super().__init__()          # base\n","        self.net = nn.Sequential(   # sequência\n","            nn.Flatten(),\n","            nn.Linear(28*28, 100),\n","            nn.ReLU(),\n","            nn.Linear(100, Z_DIM_SPARSE_AE),\n","            nn.Sigmoid(),\n","        )\n","    def forward(self, x):           # forward\n","        return self.net(x)          # retorna código\n","\n","# Decoder esparso\n","class SparseDecoder(nn.Module):\n","    def __init__(self):             # construtor\n","        super().__init__()          # base\n","        self.net = nn.Sequential(   # sequência\n","            nn.Linear(Z_DIM_SPARSE_AE, 100),\n","            nn.ReLU(),\n","            nn.Linear(100, 28*28),\n","        )\n","    def forward(self, z):           # forward\n","        x = self.net(z)             # aplica camadas\n","        x = x.view(-1, 28, 28)      # reshape para imagem\n","        return x                    # retorna reconstrução\n","\n","# AE esparso\n","class SparseAE(nn.Module):\n","    def __init__(self):                 # construtor\n","        super().__init__()              # base\n","        self.encoder = SparseEncoder()  # instancia encoder\n","        self.decoder = SparseDecoder()  # instancia decoder\n","    def forward(self, x):               # forward\n","        z = self.encoder(x)             # codifica\n","        x_hat = self.decoder(z)         # decodifica\n","        return x_hat, z                 # retorna reconstrução e código\n","\n","sparse_ae = SparseAE().to(device)  # instancia AE esparso"],"metadata":{"id":"31jiuC8OO84e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Remoção de ruído"],"metadata":{"id":"jnmJ0QO6Ozxn"}},{"cell_type":"code","source":["# Encoder com dropout\n","class DropoutEncoder(nn.Module):\n","    def __init__(self, p=0.5):              # construtor com probabilidade\n","        super().__init__()                  # base\n","        self.net = nn.Sequential(           # sequência de camadas\n","            nn.Flatten(),\n","            nn.Dropout(p=p),\n","            nn.Linear(28*28, 100),\n","            nn.ReLU(),\n","            nn.Linear(100, Z_DIM_DENOISING_AE),\n","            nn.ReLU())\n","    def forward(self, x):                   # forward\n","        return self.net(x)                  # retorna código\n","\n","# Decoder denso\n","class DropoutDecoder(nn.Module):\n","    def __init__(self):                     # construtor\n","        super().__init__()                  # base\n","        self.net = nn.Sequential(           # sequência de camadas\n","            nn.Linear(Z_DIM_DENOISING_AE, 100),\n","            nn.ReLU(),\n","            nn.Linear(100, 28*28),\n","        )\n","    def forward(self, z):                   # forward\n","        x = self.net(z)                     # aplica camadas\n","        x = x.view(-1, 28, 28)              # reshape para imagem\n","        return x                            # retorna reconstrução\n","\n","# Denoising AE\n","class DropoutAE(nn.Module):\n","    def __init__(self, p=0.5):              # construtor\n","        super().__init__()                  # base\n","        self.encoder = DropoutEncoder(p=p)  # instancia encoder\n","        self.decoder = DropoutDecoder()     # instancia decoder\n","    def forward(self, x):                   # forward\n","        z = self.encoder(x)                 # codifica\n","        x_hat = self.decoder(z)             # decodifica\n","        return x_hat, z                     # retorna reconstrução e código\n","\n","dropout_ae = DropoutAE(p=0.5).to(device)  # instancia AE com dropout 0.5"],"metadata":{"id":"-5Pk1b2aPHfk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Funções auxiliares"],"metadata":{"id":"NIkR8xiIRG__"}},{"cell_type":"code","source":["# Loop de treinamento\n","def treinar_ae(model, train_dl, valid_dl, optimizer, criterion, epochs=100, l1_regularization=False, lambda_l1=1e-4, device=device):\n","\n","    train_hist = []                             # histórico treinamento\n","    valid_hist = []                             # histórico validação\n","\n","    progress_bar = tqdm(range(epochs), desc=\"Época\", ncols=100)\n","\n","    # ---------------------- TREINAMENTO ----------------------\n","    for _ in progress_bar:                      # itera épocas\n","        model.train()                           # modo treinamento\n","        running, n = 0.0, 0                     # acumuladores\n","        for xb, yb in train_dl:                 # itera lotes de treinamento\n","            xb = xb.to(device)                  # move entrada\n","            yb = yb.squeeze(1).to(device)       # remove canal para shape (N,28,28)\n","            optimizer.zero_grad()               # zera gradientes\n","            x_hat, z = model(xb)                # forward\n","\n","            # calcula perda\n","            if l1_regularization:\n","                loss = criterion(x_hat, yb) + lambda_l1 * z.abs().mean()\n","            else:\n","                loss = criterion(x_hat, yb)\n","\n","            loss.backward()                     # retropropaga\n","            optimizer.step()                    # atualiza\n","            running += loss.item() * xb.size(0) # acumula perda\n","            n += xb.size(0)                     # acumula amostras\n","        train_loss = running / n\n","        train_hist.append(train_loss)           # guarda perda média\n","\n","        # ---------------------- VALIDAÇÃO ----------------------\n","        model.eval()                                # modo avaliação\n","        with torch.no_grad():                       # sem gradientes\n","            running, n = 0.0, 0                     # zera acumuladores\n","            for xb, yb in valid_dl:                 # itera lotes de validação\n","                xb = xb.to(device)                  # move entrada\n","                yb = yb.squeeze(1).to(device)       # remove canal\n","                x_hat, _ = model(xb)                # forward\n","                loss = criterion(x_hat, yb)         # perda\n","                running += loss.item() * xb.size(0) # acumula\n","                n += xb.size(0)                     # acumula\n","            valid_loss = running / n\n","            valid_hist.append(valid_loss)           # guarda perda média\n","\n","        progress_bar.set_postfix({\n","            \"Treino\": f\"{train_loss:.4f}\",\n","            \"Val\": f\"{valid_loss:.4f}\"\n","        })\n","\n","    return train_hist, valid_hist"],"metadata":{"id":"VEwK7Z8wRIg-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plota imagens originais e reconstruções\n","def plot_reconstructions(model, images_tensor, n_images=5, apply_clip=True, save_path: Optional[str] = None):\n","    model.eval()                                            # modo avaliação\n","    with torch.no_grad():                                   # sem gradientes\n","        x = images_tensor[:n_images].to(device)             # seleciona amostras\n","        x_hat, _ = model(x)                                 # obtém reconstruções\n","        x = x.detach().cpu().numpy()                        # move para CPU\n","        x_hat = x_hat.detach().cpu().numpy()                # move para CPU\n","        if apply_clip:                                      # aplica clipping opcional\n","            x_hat = np.clip(x_hat, 0, 1)                    # garante faixa [0,1]\n","    fig = plt.figure(figsize=(n_images * 1.5, 3))           # cria figura\n","    for i in range(n_images):                               # itera imagens\n","        plt.subplot(2, n_images, 1 + i)                     # subplot imagem original\n","        plt.imshow(x[i].squeeze(0), cmap=\"binary\")          # exibe imagem original\n","        plt.axis(\"off\")                                     # oculta eixos\n","        plt.subplot(2, n_images, 1 + n_images + i)          # subplot reconstrução\n","        plt.imshow(x_hat[i], cmap=\"binary\")                 # exibe reconstrução\n","        plt.axis(\"off\")                                     # oculta eixos\n","\n","    plt.tight_layout()\n","    if save_path:\n","        directory = os.path.dirname(save_path)\n","        if directory:\n","            os.makedirs(directory, exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","        print(f\"Plot de reconstruções salvo em: {save_path}\")\n","    else:\n","        plt.show()"],"metadata":{"id":"_zEIeJ7fTGTj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extrair_codigos(model, X_tensor, batch_size=256, device='cuda'):\n","    model.eval()  # modo avaliação\n","    with torch.no_grad():  # sem gradientes\n","        Z = []  # lista para códigos\n","        for i in range(0, X_tensor.size(0), batch_size):  # itera em blocos\n","            xb = X_tensor[i:i+batch_size].to(device)  # pega bloco\n","            _, z = model(xb)  # extrai código\n","            Z.append(z.cpu().numpy())  # acumula como numpy\n","        Z = np.concatenate(Z, axis=0)  # concatena todos\n","    return Z"],"metadata":{"id":"Aw2DiwPRTSQa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_latent_space_2d(model, X_valid, y_valid, batch_size=256, device='cuda', save_path: Optional[str] = None):\n","\n","    Z = extrair_codigos(model, X_valid, batch_size=batch_size, device=device)\n","\n","    fig = plt.figure(figsize=(10, 8))\n","    cmap = plt.cm.tab10\n","    Z = (Z - Z.min()) / (Z.max() - Z.min())  # normalize to the 0-1 range\n","    plt.scatter(Z[:, 0], Z[:, 1], c=y_valid, s=10, cmap=cmap)\n","    image_positions = np.array([[1., 1.]])\n","    for index, position in enumerate(Z):\n","        dist = ((position - image_positions) ** 2).sum(axis=1)\n","        if dist.min() > 0.02: # if far enough from other images\n","            image_positions = np.r_[image_positions, [position]]\n","\n","            # Adiciona imagem\n","            imagebox = mpl.offsetbox.AnnotationBbox(\n","                mpl.offsetbox.OffsetImage(X_valid[index].squeeze(0), cmap=\"binary\"),\n","                position, bboxprops={\"edgecolor\": cmap(y_valid[index]), \"lw\": 2})\n","            plt.gca().add_artist(imagebox)\n","\n","\n","            # Escreve as coordenadas [z1, z2] acima da imagem\n","            z1, z2 = position\n","            plt.text(\n","                z1, z2 + 0.05,                    # ligeiramente acima da imagem\n","                f\"[{z1:.2f}, {z2:.2f}]\",          # formatação com 2 casas decimais\n","                fontsize=8, fontweight='bold', ha=\"center\", va=\"bottom\",\n","                color='k'        # mesma cor da borda\n","            )\n","\n","\n","\n","    plt.axis(\"off\")\n","    if save_path:\n","        directory = os.path.dirname(save_path)\n","        if directory:\n","            os.makedirs(directory, exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","        print(f\"Plot do espaço latente salvo em: {save_path}\")\n","    else:\n","        plt.show()"],"metadata":{"id":"JDgvmcokTLda"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def curvas_de_treinamento(train_hist, valid_hist, save_path: Optional[str] = None):\n","    fig = plt.figure(figsize=(5,3))                   # cria figura\n","    plt.plot(train_hist, label=\"treinamento\")   # plota perda de treino\n","    plt.plot(valid_hist, label=\"validação\")     # plota perda de validação\n","    plt.xlabel(\"Época\")                         # rótulo eixo x\n","    plt.ylabel(\"MSE\")                           # rótulo eixo y\n","    plt.legend()                                # legenda\n","    plt.grid(True)                              # grade\n","\n","    plt.tight_layout()\n","\n","    if save_path:\n","        directory = os.path.dirname(save_path)\n","        if directory:\n","            os.makedirs(directory, exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","        print(f\"Plot das curvas de treinamento salvo em: {save_path}\")\n","    else:\n","        plt.show()"],"metadata":{"id":"h95gxGeOTWZD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def salvar_sumario_arquitetura(model, input_size, save_path: str):\n","    # Guarda o resultado do summary do torchinfo\n","    summary_stats = summary(model, input_size=input_size, col_names=(\"input_size\", \"output_size\", \"num_params\"), verbose=0)\n","\n","    # Converte para string.\n","    summary_text = str(summary_stats)\n","\n","    # Cria uma figura do Matplotlib para desenhar o texto\n","    fig = plt.figure(figsize=(12, 8))\n","    ax = fig.add_subplot(111)\n","    ax.axis('off')\n","\n","    # Adiciona o texto à figura\n","    fig.text(0.05, 0.95, summary_text, transform=fig.transFigure,\n","             ha=\"left\", va=\"top\", fontfamily='monospace', fontsize=8)\n","\n","    directory = os.path.dirname(save_path)\n","    if directory:\n","        os.makedirs(directory, exist_ok=True)\n","\n","    # Salva em PDF\n","    fig.savefig(save_path, format='pdf', bbox_inches='tight')\n","    plt.close(fig)\n","    print(f\"Sumário do modelo salvo em: {save_path}\")"],"metadata":{"id":"mO-y-9JGHhst"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Experimento"],"metadata":{"id":"lX7olLHJP3Nx"}},{"cell_type":"code","source":["def executar_e_plotar_experimento(\n","    nome_experimento: str,\n","    tipo_autoencoder: str,\n","    output_dir: str\n","):\n","    print(f\"\\n==============================================\")\n","    print(f\"  Executando: {nome_experimento}\")\n","    print(f\"==============================================\\n\")\n","\n","    ae = None\n","    l1_reg = False\n","\n","    if tipo_autoencoder == \"conv\":\n","        ae = conv_ae\n","    elif tipo_autoencoder == \"sparse\":\n","        ae = sparse_ae\n","        l1_reg = True\n","    elif tipo_autoencoder == \"dropout\":\n","        ae = dropout_ae\n","\n","    salvar_sumario_arquitetura(\n","        ae,\n","        input_size=(1, 1, 28, 28),\n","        save_path=f\"{output_dir}/{nome_experimento}_sumario.pdf\"\n","    )\n","\n","    criterion = nn.MSELoss()\n","    optimizer = optim.NAdam(ae.parameters(), lr=0.002)\n","    train_hist, valid_hist = treinar_ae(ae, train_dl, valid_dl, optimizer, criterion, epochs=N_EPOCHS, device=device, l1_regularization=l1_reg, lambda_l1=1e-4)\n","\n","\n","    plot_reconstructions(ae, X_valid.float(), n_images=10, apply_clip=True,\n","                         save_path=f\"{output_dir}/{nome_experimento}_reconstrucoes.pdf\")\n","\n","    if tipo_autoencoder == \"conv\":\n","        plot_latent_space_2d(ae, X_valid, y_valid, batch_size=256, device=device,\n","                             save_path=f\"{output_dir}/{nome_experimento}_espaco_latente.pdf\")\n","\n","    curvas_de_treinamento(train_hist, valid_hist,\n","                          save_path=f\"{output_dir}/{nome_experimento}_curvas.pdf\")\n","\n"],"metadata":{"id":"aBVXxuxWP4bm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Tarefa\n","\n","1. Replique o experimeto com o conjunto de dados `MNIST` do Pytorch:\n","    ``` python\n","    train_full  = datasets.MNIST(root=\"data\", train=True, download=True)     # carrega conjunto de treinamento\n","    test_ds     = datasets.MNIST(root=\"data\", train=False, download=True)    # carrega conjunto de teste\n","    ```\n","\n","  e os seguintes Autoencoders: convolucional, esparso e por remoção de ruído. Para cada modelo teste 3 valores distintos para a dimensionalidade do espaço latente.\n","\n","- Capture a perda (MSE) por época.\n","- Mostre as reconstruções\n","\n","**Entregáveis**:\n","1. Notebook `.ipynb`.\n","2. Relatório `.pdf`:\n","    - Reporte e comente os resultados no relatório.\n","    - Incluir gráficos gerados."],"metadata":{"id":"z5TIaHOrAQCi"}},{"cell_type":"code","source":["# --- Convolucional ---\n","executar_e_plotar_experimento(\n","    nome_experimento=\"conv_ae\",\n","    tipo_autoencoder=\"conv\",\n","    output_dir=output_dir\n",")"],"metadata":{"id":"SDiyCx51S6EK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Esparso ---\n","executar_e_plotar_experimento(\n","    nome_experimento=\"sparse_ae\",\n","    tipo_autoencoder=\"sparse\",\n","    output_dir=output_dir\n",")"],"metadata":{"id":"WcDruDJ9WYWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- Remoção de ruído ---\n","executar_e_plotar_experimento(\n","    nome_experimento=\"dropout_ae\",\n","    tipo_autoencoder=\"dropout\",\n","    output_dir=output_dir\n",")"],"metadata":{"id":"abDoSnRqWZEv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!zip -r /content/resultados_plots.zip /content/resultados_plots"],"metadata":{"id":"7QOxMeWLWSYd"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1AK3Eg1_6xHuWmDMXpm9inPO7H5Dgebc4","timestamp":1760385593136}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"},"nav_menu":{"height":"381px","width":"453px"},"toc":{"navigate_menu":true,"number_sections":true,"sideBar":true,"threshold":6,"toc_cell":false,"toc_section_display":"block","toc_window_display":false}},"nbformat":4,"nbformat_minor":0}