{"cells":[{"cell_type":"markdown","metadata":{"id":"9af74Nwj3BIy"},"source":["# IMD3004 - IA Generativa"]},{"cell_type":"markdown","metadata":{"id":"_pwt8WA-3EGx"},"source":["### Professor: Dr. Leonardo Enzo Brito da Silva"]},{"cell_type":"markdown","metadata":{"id":"ZrrRZuYa3FxY"},"source":["### Aluno: João Antonio Costa Paiva Chagas"]},{"cell_type":"markdown","metadata":{"id":"YzlLmMZuCotX"},"source":["Código adaptado de:\n","\n","[1] Sebastian Raschka,Yuxi (Hayden) Liu e e Vahid Mirjalili. Machine Learning with PyTorch and Scikit-Learn. [capítulo 17] [(Github link)](https://github.com/rasbt/machine-learning-book)\n","\n","Referências adicionais:\n","\n","[1] T. Kynkäänniemi et al., “Improved Precision and Recall Metric for Assessing Generative Models,” Adv. Neural Inf. Process. Syst., vol. 32, no. NeurIPS, Apr. 2019. [(Paper link)](https://proceedings.neurips.cc/paper_files/paper/2019/file/0234c510bc6d908b28c70ff313743079-Paper.pdf)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"loMWBcUmxiCM"},"source":["## Importações e Ambiente"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xRDo9gDfoS63"},"outputs":[],"source":["!pip install prdc torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0II-iPCmoVje"},"outputs":[],"source":["import torch                                # Importa a biblioteca principal do PyTorch, usada para computação com tensores\n","from torch import nn                        # Importa o módulo 'nn' do PyTorch, utilizado para criar e treinar redes neurais\n","from torch.utils.data import Subset, DataLoader  # Subset permite criar subconjuntos de datasets, e DataLoader facilita o carregamento de dados em mini-lotes.\n","from torchvision import datasets            # Importa o módulo de conjuntos de dados do torchvision, que fornece acesso a conjuntos de dados populares como MNIST, CIFAR, etc. para visão computacional\n","from torchvision import transforms          # Importa o módulo de transforms do torchvision, usado para pré-processar imagens (conversão em tensor, normalização, etc.).\n","from torchinfo import summary               # Importa a função summary da biblioteca torchinfo, usada para exibir a arquitetura do modelo\n","import numpy as np                          # Importa a biblioteca NumPy, usada para operações numéricas eficientes com arrays e matrizes.\n","import matplotlib.pyplot as plt             # Importa o módulo de visualização matplotlib para gerar gráficos.\n","from IPython.display import Image           # Importa a classe Image do IPython, usada para exibir imagens diretamente dentro de notebooks.\n","import os                                   # Importa o módulo padrão do Python para interagir com o sistema operacional (ex.: criar pastas, manipular caminhos de arquivos).\n","from prdc import compute_prdc               # Importa a função compute_prdc, usada para calcular as métricas de Precisão e Revocação para modelos generativos.\n","import seaborn as sns                       # Importa a biblioteca de visualização seaborn.\n","import pandas as pd                         # Importa a biblioteca pandas, usada para manipulação e análise de dados em estruturas como DataFrames.\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\" # Define uma variável de ambiente para evitar conflitos de biblioteca durante a execução em alguns ambientes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1W03wKbCotb"},"outputs":[],"source":["# Para figuras geradas pelo matplotlib serem exibidas diretamente no notebook\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89AxuYvVCotc"},"outputs":[],"source":["print(\"PyTorch version:\", torch.__version__)            # Mostra a versão instalada do PyTorch\n","print(\"GPU Available:\", torch.cuda.is_available())      # Indica se há GPU CUDA disponível\n","device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\" # Usa acelerador disponível (CUDA/MPS/XPU) ou então usa CPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Gcs6M2n0uZI"},"outputs":[],"source":["if not os.path.exists('files'):\n","    os.makedirs('files')"]},{"cell_type":"markdown","metadata":{"id":"x05BnCPI16Uw"},"source":["## Dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DvTdHQFuxiCU"},"outputs":[],"source":["image_path = './'                                         # Define o diretório raiz onde o conjunto de dados MNIST será armazenado.\n","\n","transform = transforms.Compose([                           # Define uma sequência de transformações a serem aplicadas às imagens do dataset.\n","    transforms.ToTensor(),                                 # Converte as imagens PIL em tensores PyTorch.\n","    transforms.Normalize(mean=(0.5), std=(0.5)),           # Normaliza os valores dos pixels para a faixa [-1, 1], com média 0.5 e desvio 0.5.\n","])\n","\n","mnist_dataset = datasets.MNIST(root=image_path,            # Cria o objeto do dataset MNIST.\n","                               train=True,                 # Define que serão carregadas as imagens do conjunto de treinamento.\n","                               transform=transform,        # Aplica as transformações definidas acima a cada imagem carregada.\n","                               download=True)              # Faz o download do dataset caso ele não esteja presente no diretório especificado.\n","\n","mnist_test = datasets.MNIST(root=image_path,               # Cria o objeto do dataset MNIST.\n","                               train=False,                # Define que serão carregadas as imagens do conjunto de teste.\n","                               transform=transform,        # Aplica as transformações definidas acima a cada imagem carregada.\n","                               download=True)              # Faz o download do dataset caso ele não esteja presente no diretório especificado.\n","\n","print(f'mnist_dataset | mnist_test: {type(mnist_dataset)} | {type(mnist_test)}.')\n","\n","example, label = next(iter(mnist_dataset))                 # Obtém o primeiro par (imagem, rótulo) do dataset MNIST.\n","print(f'Min: {example.min()} Max: {example.max()}')        # Exibe os valores mínimo e máximo do tensor da imagem (após normalização).\n","print(example.shape)                                       # Exibe o formato do tensor da imagem (para MNIST: [1, 28, 28])."]},{"cell_type":"markdown","metadata":{"id":"-wGs8cr2sC1d"},"source":["## Classificador"]},{"cell_type":"markdown","metadata":{"id":"2ryarzztsHZB"},"source":["### Modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C_bOoOLZsEQf"},"outputs":[],"source":["# Classificador dividido em dois nn.Sequential: feature_extractor + classifier_head\n","\n","# Extrator de features\n","feature_extractor = nn.Sequential(\n","    nn.Conv2d(1, 32, 3), nn.ReLU(), nn.MaxPool2d(2),    # -> (B,32,13,13)\n","    nn.Conv2d(32, 64, 3), nn.ReLU(), nn.MaxPool2d(2),   # -> (B,64,5,5)\n","    nn.Conv2d(64, 128, 3), nn.ReLU(),                   # -> (B,128,3,3)\n","    nn.AdaptiveAvgPool2d(1),                            # -> (B,128,1,1)\n","    nn.Flatten()                                        # -> (B,128)\n",").to(device)\n","\n","# Cabeça classificadora\n","classifier_head = nn.Sequential(\n","    nn.Linear(128, 10)                                  # -> (B,10)\n",").to(device)\n","\n","# Modelo completo\n","full_model = nn.Sequential(\n","    feature_extractor,\n","    classifier_head\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wAyuRj1L16U1"},"outputs":[],"source":["# Extrator de features\n","summary(feature_extractor, input_size=(1, 1, 28, 28))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BttPOQ9j16U1"},"outputs":[],"source":["# Cabeça classificadora\n","summary(classifier_head, input_size=(1, 128))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IaibtfoO16U1"},"outputs":[],"source":["# Modelo completo\n","summary(full_model, input_size=(1, 1, 28, 28))"]},{"cell_type":"markdown","metadata":{"id":"sjcM6M1esGYF"},"source":["### Treinamento do classificador"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4sSBDN_9sKUR"},"outputs":[],"source":["## Função de perda e otimizadores\n","loss_fn = nn.CrossEntropyLoss(reduction='sum')\n","optimizer = torch.optim.Adam(full_model.parameters(), lr=1e-3)\n","\n","## Preparação do conjunto de dados\n","train_dl = DataLoader(mnist_dataset, batch_size=128, shuffle=True,  drop_last=True)\n","test_dl  = DataLoader(mnist_test,    batch_size=512, shuffle=False, drop_last=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c5vloDtY16U2"},"outputs":[],"source":["def train_one_epoch(dataloader, model, loss_fn, optimizer):\n","    model.train()                                               # Coloca o modelo em modo de treinamento (ativa dropout, batchnorm, etc.)\n","    total_loss, total, correct = 0.0, 0, 0                      # Inicializa acumuladores de perda, número de exemplos e acertos\n","    for x, y in dataloader:                                     # Itera pelos lotes de dados\n","        x, y = x.to(device), y.to(device)                       # Move entradas e rótulos para o dispositivo (CPU/GPU)\n","        logits = model(x)                                       # Calcula as predições do modelo\n","        loss = loss_fn(logits, y)                               # Calcula a perda entre predições e rótulos\n","        optimizer.zero_grad()                                   # Zera gradientes acumulados\n","        loss.backward()                                         # Calcula gradientes via backpropagation\n","        optimizer.step()                                        # Atualiza os parâmetros do modelo\n","        total_loss += loss.item()                               # Acumula a perda do lote\n","        correct    += (logits.argmax(1) == y).sum().item()      # Conta acertos comparando previsão com rótulo\n","        total      += x.size(0)                                 # Conta número de exemplos processados\n","    return total_loss/total, correct/total                      # Retorna perda média por exemplo e acurácia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ouYEwbQUui_R"},"outputs":[],"source":["@torch.no_grad()                                                 # Desativa o cálculo de gradientes (avaliação mais rápida e com menor uso de memória)\n","def evaluate(dataloader, model, loss_fn):\n","    model.eval()                                                 # Coloca o modelo em modo de avaliação (desativa dropout, batchnorm usa estatísticas fixas)\n","    total_loss, total, correct = 0.0, 0, 0                       # Inicializa acumuladores de perda, número de exemplos e acertos\n","    for x, y in dataloader:                                      # Itera pelos lotes de dados\n","        x, y = x.to(device), y.to(device)                        # Move entradas e rótulos para o dispositivo (CPU/GPU)\n","        logits = model(x)                                        # Calcula as predições do modelo\n","        loss = loss_fn(logits, y)                                # Calcula a perda entre predições e rótulos\n","        total_loss += loss.item()                                # Acumula a perda do lote\n","        correct    += (logits.argmax(1) == y).sum().item()       # Conta acertos comparando previsão com rótulo\n","        total      += x.size(0)                                  # Conta número de exemplos processados\n","    return total_loss/total, correct/total                       # Retorna perda média por exemplo e acurácia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NtZPUV4kutb8"},"outputs":[],"source":["n_epocas = 10                                                                                       # Define o número total de épocas de treinamento\n","for ep in range(n_epocas):                                                                          # Loop principal sobre as épocas\n","    tr_loss, tr_acc = train_one_epoch(train_dl, full_model, loss_fn, optimizer)                     # Executa uma época de treinamento e retorna perda/acurácia\n","    te_loss, te_acc = evaluate(test_dl, full_model, loss_fn)                                        # Avalia o modelo no conjunto de teste e retorna perda/acurácia\n","    print(f\"Época {ep + 1}/{n_epocas} | Treinamento: perda={tr_loss:.4f} acc={tr_acc:.3f} | \"\n","          f\"Teste: perda={te_loss:.4f} acc={te_acc:.3f}\")                                          # Imprime resultados formatados de treino e teste\n"]},{"cell_type":"markdown","metadata":{"id":"bOt1FGen60eV"},"source":["## Funções Auxiliares"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fFCs9jba68nL"},"outputs":[],"source":["def create_noise(batch_size, z_size, mode_z):\n","    \"\"\"Gera um tensor de ruído (vetor latente).\"\"\"\n","    if mode_z == 'uniform':\n","        input_z = torch.rand(batch_size, z_size, device=device) * 2 - 1\n","    elif mode_z == 'normal':\n","        input_z = torch.randn(batch_size, z_size, device=device)\n","    return input_z"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qw-3gTzr6-hm"},"outputs":[],"source":["@torch.no_grad()\n","def get_features(dataset, feature_extractor, N: int, batch_size: int = 512) -> np.ndarray:\n","    \"\"\"Extrai features de um conjunto de dados real.\"\"\"\n","    feature_extractor.eval()\n","    subset = Subset(dataset, range(min(N, len(dataset))))\n","    loader = DataLoader(subset, batch_size=batch_size, shuffle=False, drop_last=False)\n","    feats_list = []\n","    for x, _ in loader:\n","        x = x.to(device)\n","        emb = feature_extractor(x)\n","        feats_list.append(emb.cpu().numpy().astype(np.float32))\n","    return np.concatenate(feats_list, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D44K5t577AYk"},"outputs":[],"source":["@torch.no_grad()\n","def get_features_from_generator(gen_model, feature_extractor, N: int, z_dim: int, mode_z: str, batch_size: int, image_size: tuple) -> np.ndarray:\n","    \"\"\"Gera imagens e extrai suas features.\"\"\"\n","    gen_model.eval()\n","    feature_extractor.eval()\n","    feats = []\n","    remaining = N\n","    while remaining > 0:\n","        cur = min(batch_size, remaining)\n","        z = create_noise(cur, z_dim, mode_z)\n","        # Check if the model is a conditional WGAN and requires labels\n","        if hasattr(gen_model, 'label_embedding'):\n","            labels = torch.randint(0, 10, (cur,), device=device) # Generate random labels for MNIST (0-9)\n","            imgs = gen_model(z, labels).view(cur, 1, *image_size)\n","        else:\n","            # Garante que a saída do gerador tenha o formato [B, C, H, W]\n","            imgs = gen_model(z).view(cur, 1, *image_size)\n","\n","        emb = feature_extractor(imgs)\n","        feats.append(emb.cpu().numpy().astype(np.float32))\n","        remaining -= cur\n","    return np.concatenate(feats, axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m77YEsGm7Crn"},"outputs":[],"source":["def mpr_curve_by_k(real_feats, fake_feats, ks):\n","    \"\"\"Calcula precisão e revocação para uma lista de valores k.\"\"\"\n","    prec, rec = [], []\n","    for k in ks:\n","        print(f'Calculando MPR para k={k}...')\n","        m = compute_prdc(real_feats, fake_feats, nearest_k=k)\n","        prec.append(m['precision'])\n","        rec.append(m['recall'])\n","    return np.array(rec), np.array(prec)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"adRqOFXzAQNc"},"outputs":[],"source":["def mpr_sweep_Nk(\n","    mnist_test_dataset,\n","    gen_model,\n","    feature_extractor,\n","    Ns=(1000, 2500, 5000, 7500, 10000),\n","    ks=(3, 5, 10),\n","    *,\n","    model_name='GAN',\n","    batch_size=512,\n","    z_dim=100,\n","    mode_z='uniform',\n","    image_size=(28, 28)\n",") -> pd.DataFrame:\n","    \"\"\"\n","    Executa uma varredura (sweep) sobre diferentes valores de N (nº de amostras)\n","    e k (vizinhos mais próximos) para calcular a precisão e a revocação.\n","\n","    Retorna:\n","        pd.DataFrame: Um DataFrame com os resultados para cada combinação de N e k.\n","    \"\"\"\n","    linhas = []\n","    for N in Ns:\n","        # Extrai as features uma vez para cada valor de N\n","        print(f\"  [N={N}] Extraindo features reais e geradas...\")\n","        real_feats = get_features(mnist_test_dataset, feature_extractor, N=N, batch_size=batch_size)\n","        fake_feats = get_features_from_generator(\n","            gen_model, feature_extractor, N, z_dim, mode_z, batch_size, image_size\n","        )\n","\n","        # Calcula as métricas para diferentes valores de k\n","        for k in ks:\n","            m = compute_prdc(\n","                real_features=real_feats.astype('float32'),\n","                fake_features=fake_feats.astype('float32'),\n","                nearest_k=k\n","            )\n","            # Adiciona os resultados à lista\n","            linhas.append({\n","                'modelo':    model_name,\n","                'N':         int(N),\n","                'k':         int(k),\n","                'precision': float(m['precision']),\n","                'recall':    float(m['recall'])\n","            })\n","            print(f\"    [modelo={model_name}] N={N} | k={k} -> Precisão={m['precision']:.4f} | Revocação={m['recall']:.4f}\")\n","\n","    return pd.DataFrame(linhas)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aFqaZMUlATag"},"outputs":[],"source":["def plot_mpr_df(df: pd.DataFrame):\n","    \"\"\"\n","    Plota os resultados da varredura de Precisão e Revocação a partir de um DataFrame.\n","\n","    Cria uma linha de gráficos (Precisão vs N, Revocação vs N) para cada modelo\n","    encontrado no DataFrame.\n","    \"\"\"\n","    modelos = df['modelo'].unique().tolist()\n","    n_models = len(modelos)\n","\n","    fig, axes = plt.subplots(\n","        n_models, 2,\n","        figsize=(14, 5 * n_models),\n","        dpi=100,\n","        constrained_layout=True,\n","        squeeze=False # Garante que 'axes' seja sempre 2D\n","    )\n","\n","    for i, modelo in enumerate(modelos):\n","        df_model = df[df['modelo'] == modelo].copy()\n","\n","        # --- Gráfico da Esquerda: Precisão ---\n","        ax_left = axes[i, 0]\n","        sns.lineplot(\n","            data=df_model, x='N', y='precision',\n","            hue='k', marker='o', ax=ax_left, palette='viridis'\n","        )\n","        ax_left.set_title(f'Precisão vs N ({modelo})', fontsize=14)\n","        ax_left.set_xlabel('N (número de imagens)', fontsize=12)\n","        ax_left.set_ylabel('Precisão (Qualidade)', fontsize=12)\n","        ax_left.set_ylim(0, 1) # Fixa o eixo Y entre 0 e 1\n","        ax_left.grid(True, linestyle='--', alpha=0.5)\n","        ax_left.legend(title='k')\n","\n","        # --- Gráfico da Direita: Revocação ---\n","        ax_right = axes[i, 1]\n","        sns.lineplot(\n","            data=df_model, x='N', y='recall',\n","            hue='k', marker='o', ax=ax_right, palette='viridis'\n","        )\n","        ax_right.set_title(f'Revocação vs N ({modelo})', fontsize=14)\n","        ax_right.set_xlabel('N (número de imagens)', fontsize=12)\n","        ax_right.set_ylabel('Revocação (Diversidade)', fontsize=12)\n","        ax_right.set_ylim(0, 1) # Fixa o eixo Y entre 0 e 1\n","        ax_right.grid(True, linestyle='--', alpha=0.5)\n","        ax_right.legend(title='k')\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnviY8Ye7Hs9"},"outputs":[],"source":["def load_model(model_path, device):\n","    \"\"\"Carrega um modelo salvo e o configura para o modo de avaliação.\"\"\"\n","    loaded_model = torch.jit.load(model_path, map_location=device)\n","    loaded_model.eval()\n","    return loaded_model"]},{"cell_type":"markdown","metadata":{"id":"l2uoWCH716U5"},"source":["## Tarefa\n","\n","1. Treinar os seguintes modelos utilizando o conjunto de **treinamento** MNIST:\n","\n","- GAN (com camadas completamente conectadas, isto é, GAN **NÃO** convolucional)\n","- DCGAN (convolucional)\n","- WGAN (convolucional)\n","\n","Observação: A utilização dos laboratórios anteriores é permitida. Nesse caso, salvar os modelos treinados e carregar tais modelos aqui.\n","\n","2. Comparar os modelos utilizando as curvas de MPR para diferentes valores do parâmetro `k` (mostre os gráficos com legendas para os modelos). Utilize o conjunto de **teste** MNIST para a aproximação da variedade dos dados reais.\n","\n","- Qual o comportamento da precisão e revocação ao se aumentar o valor de k?\n","\n","3. Varie o número de imagens `N=[1000, 2500, 5000, 7500, 10000]` utilizadas (utilize o mesmo valor para o número de imagens reais e o número de imagens geradas) no cálculo da precisão e revocação. Observe o comportamento das curvas de precisão e revocação (para `k=[3, 5, 10]`) para cada modelo.\n","\n","- Mostrar 3 gráficos, um para cada modelo.\n","\n","**Entregáveis**:\n","1. Notebook `.ipynb`.\n","2. Relatório `.pdf`:\n","\n","    - Reporte e comente os resultados no relatório.\n","\n","    - Incluir gráficos gerados.\n"]},{"cell_type":"markdown","metadata":{"id":"_1r738K-0eF4"},"source":["### 1:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HlHTRG0_0gx4"},"outputs":[],"source":["generator_gan = load_model('files/mnist_generator_nonconv_gan.pt', device)\n","generator_dcgan = load_model('files/mnist_generator_conv_dcgan.pt', device)\n","generator_wgan = load_model('files/mnist_conditional_conv_wgan.pt', device)"]},{"cell_type":"markdown","metadata":{"id":"V-xaN5BL4BeJ"},"source":["### 2:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s_68cDWm4CD5"},"outputs":[],"source":["image_size = (28, 28)\n","z_size = 100\n","mode_z = 'uniform'\n","batch_size_eval = 512\n","\n","N = 10_000\n","ks = list(range(1, 11))\n","feature_extractor = full_model[0]\n","dataset = mnist_test\n","\n","generators = {\n","    'GAN (FC)': generator_gan,\n","    'DCGAN': generator_dcgan,\n","    'WGAN': generator_wgan\n","}\n","\n","results = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mS0Usikd4T4u"},"outputs":[],"source":["real_features = get_features(dataset, feature_extractor, N, batch_size_eval)\n","print(f\"Shape das features reais: {real_features.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSX5E8Xu4Wy-"},"outputs":[],"source":["for name, model in generators.items():\n","    print(f\"\\nProcessando o modelo: {name}\")\n","\n","    # Extrair features das imagens geradas pelo modelo atual\n","    fake_features = get_features_from_generator(\n","        model,\n","        feature_extractor,\n","        N,\n","        z_size,\n","        mode_z,\n","        batch_size_eval,\n","        image_size\n","    )\n","\n","    # Calcular a curva MPR variando k\n","    rec, prec = mpr_curve_by_k(real_features, fake_features, ks)\n","    results[name] = {'recall': rec, 'precision': prec}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SarJ-7UA4cza"},"outputs":[],"source":["plt.figure(figsize=(10, 8))\n","for name, data in results.items():\n","    plt.plot(data['recall'], data['precision'], marker='o', label=name)\n","\n","# Anotar pontos de k para o WGAN (ou o último modelo da lista)\n","if 'WGAN' in results:\n","    wgan_results = results['WGAN']\n","    for r, p, k in zip(wgan_results['recall'], wgan_results['precision'], ks):\n","        if k in [1, 3, 5, 7, 10]:\n","            plt.text(r + 0.005, p, f'k={k}')\n","\n","plt.xlim(0, 1); plt.ylim(0, 1)\n","plt.xlabel('Revocação ( mede a diversidade )', fontsize=14)\n","plt.ylabel('Precisão ( mede a qualidade )', fontsize=14)\n","plt.title('Curva MPR: Comparação de Modelos (N=10.000)', fontsize=16)\n","plt.grid(True, linestyle='--', alpha=0.6)\n","plt.legend(fontsize=12)\n","plt.gca().set_aspect('equal', adjustable='box')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"qDOBjvsk_YIC"},"source":["### 3:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLKQTqzh_ZA2"},"outputs":[],"source":["Ns_sweep = (1000, 2500, 5000, 7500, 10000)\n","ks_sweep = (3, 5, 10)\n","\n","all_dfs = []\n","\n","for name, model in generators.items():\n","    print(f\"--- Iniciando varredura para o modelo: {name} ---\")\n","    df_model = mpr_sweep_Nk(\n","        mnist_test_dataset=mnist_test,\n","        gen_model=model,\n","        feature_extractor=feature_extractor,\n","        Ns=Ns_sweep,\n","        ks=ks_sweep,\n","        model_name=name,\n","        batch_size=batch_size_eval,\n","        z_dim=z_size,\n","        mode_z=mode_z\n","    )\n","    all_dfs.append(df_model)\n","    print(f\"--- Varredura para {name} concluída ---\\n\")\n","\n","df_final = pd.concat(all_dfs, ignore_index=True)\n","plot_mpr_df(df_final)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["-wGs8cr2sC1d"],"gpuType":"T4","provenance":[{"file_id":"1obpmmT_t9tNDEbTOojqH4cCdc15WUv0n","timestamp":1757966661262},{"file_id":"1EAc3WwjQXDJLLz-Ki7PnY55-WOlnzS0f","timestamp":1757943655929}]},"kernelspec":{"display_name":"ai","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"}},"nbformat":4,"nbformat_minor":0}