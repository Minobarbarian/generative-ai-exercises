{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["hSA-uH9HnDwG","MWy2kDrJERGh","DE4-1OsT5tgG","WJAl5QHoKNe4","B3zmdNza44fl","u3mHuYgV5d1H","gdOgx3jSNzFS"],"toc_visible":true,"authorship_tag":"ABX9TyNJ+SyNn5tY72T7QW6KFApe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# IMD3004 - IA Generativa"],"metadata":{"id":"7IlJowSa4Y6t"}},{"cell_type":"markdown","source":["### Professor: Dr. Leonardo Enzo Brito da Silva"],"metadata":{"id":"M5edkneO4dGw"}},{"cell_type":"markdown","source":["### Aluno: João Antonio Costa Paiva Chagas"],"metadata":{"id":"nYOnHe-yZvEi"}},{"cell_type":"markdown","source":["## Tarefa: Treinar uma GAN com o conjunto *Two Moons* do scikit-learn\n","\n","Utilize o código acima como base e adapte-o para o seguinte problema:\n","\n","1. Gere o conjunto de dados *Two Moons* utilizando a função `make_moons` do [`scikit-learn`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html):\n","\n","```python\n","from sklearn.datasets import make_moons\n","X, y = make_moons(n_samples=4096, noise=0.1, random_state=42)\n","```\n","\n","Obs.: lembre-se de normalizar os dados.\n","\n","2. Substitua os dados de treinamento originais do código pelo conjunto *Two Moons*.  \n","3. Treine uma GAN (com gerador e discriminador definidos no código) para aprender a distribuição do *Two Moons* (se necessário faça mudanças nas arquiteturas das redes neurais). **Não utilize parada antecipada: treine a GAN por 1000 épocas.**\n","4. Registre a evolução das perdas do gerador e do discriminador ao longo do treinamento.  \n","5. Gere gráficos comparando os dados reais (*Two Moons*) e as amostras criadas pelo gerador em diferentes épocas.  \n","6. Salve o modelo treinado e mostre como carregar e gerar novas amostras a partir dele.  \n","\n","**Entregáveis:**  \n","1. Notebook .ipynb contendo:  \n","- O código adaptado e comentado.  \n","2. Relatório em .pdf\n","- Gráficos que mostrem o processo de treinamento.  \n","- Uma breve discussão sobre o treinamento e arquitetura da GAN, bem como sobre os resultados obtidos."],"metadata":{"id":"SR7T2IbYZmsM"}},{"cell_type":"markdown","source":["### Importações:"],"metadata":{"id":"hSA-uH9HnDwG"}},{"cell_type":"code","source":["import os\n","import torch\n","import torchvision\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from sklearn.datasets import make_moons\n","import torchvision.transforms as transforms\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import DataLoader, TensorDataset"],"metadata":{"id":"_m30AxTg6l18"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ambiente:"],"metadata":{"id":"MWy2kDrJERGh"}},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"id":"ean_GJg1RfEg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not os.path.exists('files'):\n","    os.makedirs('files')"],"metadata":{"id":"5mKuUcR3ESId"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dados:"],"metadata":{"id":"DE4-1OsT5tgG"}},{"cell_type":"code","source":["def prepare_two_moons_data(batch_size):\n","    \"\"\"Gera, escala e carrega a base de dados Two Moons.\"\"\"\n","    X, y = make_moons(n_samples=4096, noise=0.1, random_state=42)\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","    training_data = torch.tensor(X_scaled, dtype=torch.float32)\n","    train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n","    return train_loader"],"metadata":{"id":"2DXch6ezSod2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_mnist_data(batch_size):\n","    \"\"\"Baixa, transforma e carrega a base de dados MNIST.\"\"\"\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))\n","    ])\n","    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","    train_loader = DataLoader(\n","        train_dataset,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","    return train_loader"],"metadata":{"id":"OPiDCyDPSsB4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def preparar_dados(dataset_choice, batch_size):\n","    \"\"\"Chama a função apropriada para preparar a base de dados escolhida.\"\"\"\n","    if dataset_choice == 'two_moons':\n","        return prepare_two_moons_data(batch_size)\n","    elif dataset_choice == 'mnist':\n","        return prepare_mnist_data(batch_size)\n","    else:\n","        raise ValueError(\"Escolha inválida. Escolha 'two_moons' ou 'mnist'.\")"],"metadata":{"id":"pd2K_A3253Rv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Plotando:"],"metadata":{"id":"WJAl5QHoKNe4"}},{"cell_type":"code","source":["def generate_samples(gen_model, device, params):\n","    \"\"\"Gera um lote de amostras pelo gerador.\"\"\"\n","    with torch.no_grad():\n","        gen_model.eval()\n","        noise = torch.randn(256, params['z_size'], device=device)\n","        generated_samples = gen_model(noise).cpu().numpy()\n","        gen_model.train()\n","    return generated_samples"],"metadata":{"id":"eM1G8gTtLmt7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_two_moons_samples(epoch, generated_samples, train_loader, dataset_choice):\n","    \"\"\"Cria e salva um scatter plot para a base de dados duas luas.\"\"\"\n","    plt.figure(figsize=(8, 8))\n","    real_data = train_loader.dataset.numpy()\n","    plt.scatter(real_data[:, 0], real_data[:, 1], c='r', alpha=0.1, label='Amostras Reais')\n","    plt.scatter(generated_samples[:, 0], generated_samples[:, 1], c='g', alpha=0.6, label='Amostras Geradas')\n","    plt.title(f'Época {epoch}')\n","    plt.legend()\n","    plt.savefig(f\"files/{dataset_choice}_p{epoch}.png\")\n","    plt.close()"],"metadata":{"id":"tTBCdl5sLm8k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_mnist_samples(epoch, generated_samples, dataset_choice):\n","    \"\"\"Cria e salva um grid de imagem para a base de dados MNIST.\"\"\"\n","    fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n","    fig.suptitle(f'Época {epoch}', fontsize=16)\n","    for i, ax in enumerate(axes.flatten()):\n","        if i < 16:\n","            img = generated_samples[i].reshape(28, 28)\n","            ax.imshow(img, cmap='gray')\n","        ax.axis('off')\n","    plt.savefig(f\"files/{dataset_choice}_p{epoch}.png\")\n","    plt.close()"],"metadata":{"id":"Xa1y36rVLnJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def log_and_save_samples(epoch, gen_model, device, params, dataset_choice, train_loader):\n","    \"\"\"Guarda os plots das amostras geradas.\"\"\"\n","    print(f\"Época {epoch}/{params['num_epochs']} | Logging samples...\")\n","\n","    # 1. Gera amostras\n","    generated_samples = generate_samples(gen_model, device, params)\n","\n","    # 2. Plota e salva baseado na base de dados\n","    if dataset_choice == 'two_moons':\n","        plot_two_moons_samples(epoch, generated_samples, train_loader, dataset_choice)\n","    elif dataset_choice == 'mnist':\n","        plot_mnist_samples(epoch, generated_samples, dataset_choice)"],"metadata":{"id":"pl_ueU6YLumB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_two_moons_evolution(dataset_choice='two_moons', epochs_to_show=[25, 100, 500, 1000]):\n","    \"\"\"Carrega os plots salvos para o Two Moons.\"\"\"\n","    print(\"Mostrando a evolução das amostras para o dataset Two Moons:\")\n","    fig, axes = plt.subplots(1, len(epochs_to_show), figsize=(20, 5))\n","    for i, epoch in enumerate(epochs_to_show):\n","        file_path = f\"files/{dataset_choice}_p{epoch}.png\"\n","        if os.path.exists(file_path):\n","            img = plt.imread(file_path)\n","            axes[i].imshow(img)\n","            axes[i].set_title(f\"Resultado na Época {epoch}\")\n","        else:\n","            axes[i].set_title(f\"Arquivo não encontrado\")\n","        axes[i].axis('off')\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"bX-23IRPKLYg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_mnist_evolution(epoch_samples):\n","    \"\"\"Plota a evolução das amostras MNIST coletadas durante o treino.\"\"\"\n","    print(\"Mostrando a evolução das amostras para o dataset MNIST:\")\n","    fig, axes = plt.subplots(len(epoch_samples), 10, figsize=(15, len(epoch_samples) * 1.5))\n","    if len(epoch_samples) == 1: axes = np.array([axes])\n","    fig.suptitle(\"Evolução das Amostras Geradas\", fontsize=16, y=1.02)\n","    for row, data in enumerate(epoch_samples):\n","        epoch_num, samples = data['epoch'], data['samples']\n","        for col in range(10):\n","            ax = axes[row, col]\n","            img = samples[col].reshape(28, 28)\n","            ax.imshow(img, cmap='gray')\n","            ax.axis('off')\n","            if col == 0:\n","                ax.text(-0.1, 0.5, f'Época {epoch_num}', ha='right', va='center', transform=ax.transAxes, fontsize=12)\n","    plt.show()"],"metadata":{"id":"4Ye5sZqJKVkY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_losses(g_losses, d_losses):\n","    \"\"\"Plota as perdas.\"\"\"\n","    plt.figure(figsize=(10, 5))\n","    plt.plot(g_losses, label='Generator Loss')\n","    plt.plot(d_losses, label='Discriminator Loss')\n","    plt.title('Evolução das Perdas da GAN')\n","    plt.xlabel('Época')\n","    plt.ylabel('Perda (BCELoss)')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()"],"metadata":{"id":"93wIt9PqKXkr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_final_samples(generated_samples, dataset_choice, train_loader):\n","    \"\"\"Exibe as amostras geradas finais.\"\"\"\n","    print(\"Amostras geradas com o modelo final carregado:\")\n","\n","    if dataset_choice == 'two_moons':\n","        plt.figure(figsize=(8, 8))\n","        real_data = train_loader.dataset.numpy()\n","        plt.scatter(real_data[:, 0], real_data[:, 1], c='r', alpha=0.1)\n","        plt.scatter(generated_samples[:, 0], generated_samples[:, 1], c='g', alpha=0.6)\n","        plt.title(\"Amostras Finais (Two Moons)\")\n","        plt.show()\n","\n","    elif dataset_choice == 'mnist':\n","        fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n","        fig.suptitle(\"Amostras Finais (MNIST)\", fontsize=16)\n","        for i, ax in enumerate(axes.flatten()):\n","            if i < 16:\n","                img = generated_samples[i].reshape(28, 28)\n","                ax.imshow(img, cmap='gray')\n","            ax.axis('off')\n","        plt.show()"],"metadata":{"id":"qcHydoscOHqq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### GAN:"],"metadata":{"id":"B3zmdNza44fl"}},{"cell_type":"markdown","source":["#### Hiperparâmetros:"],"metadata":{"id":"3gPYkVnI5fRZ"}},{"cell_type":"code","source":["def get_hyperparameters(dataset_choice):\n","    \"\"\"Retorna um dicionário de hiperparâmetros baseado na base de dados escolhida.\"\"\"\n","    if dataset_choice == 'two_moons':\n","        return {\n","            'z_size': 2, 'image_size': 2, 'lr': 0.0005, 'num_epochs': 1000, 'batch_size': 128\n","        }\n","    elif dataset_choice == 'mnist':\n","        return {\n","            'z_size': 100, 'image_size': 28 * 28, 'lr': 0.0002, 'num_epochs': 50, 'batch_size': 64\n","        }"],"metadata":{"id":"tuql1kNXf-jD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Gerador:"],"metadata":{"id":"u3mHuYgV5d1H"}},{"cell_type":"code","source":["def get_generator(dataset_choice, z_size, image_size):\n","    \"\"\"Retorna a arquitetura correta do gerador baseada na escolha da base de dados.\"\"\"\n","    if dataset_choice == 'two_moons':\n","        return nn.Sequential(\n","            nn.Linear(z_size, 16),\n","            nn.ReLU(),\n","            nn.Linear(16, 32),\n","            nn.ReLU(),\n","            nn.Linear(32, image_size)\n","        )\n","    elif dataset_choice == 'mnist':\n","        return nn.Sequential(\n","            nn.Linear(z_size, 256),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(256, 512),\n","            nn.LeakyReLU(0.2),\n","            nn.Linear(512, image_size),\n","            nn.Tanh()\n","          )"],"metadata":{"id":"rkskiRf_gaM_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_generator_step(disc_model, gen_model, optim_g, loss_fn, batch_size, device, z_size):\n","    optim_g.zero_grad()                                                         # Zera os gradientes acumulados do gerador.\n","\n","    # Gera amostras falsas\n","    noise = torch.randn(batch_size, z_size, device=device)                      # Gera ruído aleatório\n","    fake_samples = gen_model(noise)                                             # Gerador produz imagens falsas a partir do ruído.\n","\n","    # Calcula perda baseado na saída do discriminador\n","    g_output = disc_model(fake_samples)                                         # Avalia as amostras geradas no discriminador.\n","    g_loss = loss_fn(g_output, torch.ones_like(g_output))                       # Calcula a perda do gerador\n","\n","    # Atualiza Pesos\n","    g_loss.backward()                                                           # Propaga os gradientes no grafo do gerador.\n","    optim_g.step()                                                              # Atualiza os pesos do gerador.\n","\n","    return g_loss.item()"],"metadata":{"id":"zhHT7DMDOM-i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Discriminador:"],"metadata":{"id":"00lSiR2vOHHK"}},{"cell_type":"code","source":["def get_discriminator(dataset_choice, image_size):\n","    \"\"\"Retorna a arquitetura correta do discriminador baseada na escolha da base de dados.\"\"\"\n","    if dataset_choice == 'two_moons':\n","        return nn.Sequential(\n","            nn.Linear(image_size, 256),\n","            nn.ReLU(), nn.Dropout(0.3),\n","            nn.Linear(256, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(64, 1),\n","            nn.Sigmoid()\n","        )\n","    elif dataset_choice == 'mnist':\n","        return nn.Sequential(\n","            nn.Linear(image_size, 512),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.3),\n","            nn.Linear(512, 256),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.3),\n","            nn.Linear(256, 1),\n","            nn.Sigmoid()\n","        )"],"metadata":{"id":"SGkem4_chHMX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_discriminator_step(disc_model, gen_model, optim_d, loss_fn, real_samples, device, z_size, dataset_choice):\n","    optim_d.zero_grad()                                                         # Zera os gradientes acumulados do discriminador\n","    current_batch_size = real_samples.size(0)                                   # Obtém o tamanho do lote (número de amostras).\n","\n","    if dataset_choice == 'mnist':                                               # Achata imagens se for MNIST\n","        real_samples = real_samples.view(current_batch_size, -1)\n","    real_samples = real_samples.to(device)\n","\n","    # Calcula a perda nas amostras reais\n","    d_real_output = disc_model(real_samples)\n","    d_real_loss = loss_fn(d_real_output, torch.ones_like(d_real_output))        # Calcula a perda do discriminador para o lote real.\n","\n","    # Calcula a perda nas amostras falsas\n","    noise = torch.randn(current_batch_size, z_size, device=device)              # Gera ruído aleatório\n","    fake_samples = gen_model(noise)                                             # Gerador produz imagens falsas a partir do ruído.\n","    d_fake_output = disc_model(fake_samples.detach())                           # Passa as imagens falsas pelo discriminador e obtém a saída\n","    d_fake_loss = loss_fn(d_fake_output, torch.zeros_like(d_fake_output))       # Calcula a perda do discriminador para o lote falso.\n","\n","    # Soma as perdas e atualiza os pesos\n","    d_loss = (d_real_loss + d_fake_loss) / 2                                    # Combina as perdas do lote real e falso.\n","    d_loss.backward()                                                           # Propaga os gradientes da perda total.\n","    optim_d.step()                                                              # Atualiza os parâmetros do discriminador.\n","\n","    return d_loss.item()"],"metadata":{"id":"Gc_oe3SnN_Ta"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Treinamento:"],"metadata":{"id":"EyUvfr3U8lxx"}},{"cell_type":"code","source":["def setup_training_components(gen_model, disc_model, device, params, dataset_choice):\n","    \"\"\"Inicializa todos os componentes necessários para o treinamento.\"\"\"\n","    components = {\n","        'loss_fn': nn.BCELoss(),\n","        'optim_d': optim.Adam(disc_model.parameters(), lr=params['lr']),\n","        'optim_g': optim.Adam(gen_model.parameters(), lr=params['lr']),\n","        'g_losses': [],\n","        'd_losses': [],\n","        'epoch_samples_mnist': [],\n","        'fixed_noise_mnist': None\n","    }\n","    if dataset_choice == 'mnist':\n","        components['fixed_noise_mnist'] = torch.randn(64, params['z_size'], device=device)\n","    return components"],"metadata":{"id":"4_aTPDavQZrR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(gen_model, disc_model, train_loader, loss_fn, optim_d, optim_g, device, params, dataset_choice):\n","    \"\"\"Executa uma única época de treinamento para a GAN.\"\"\"\n","    epoch_g_loss, epoch_d_loss = 0.0, 0.0\n","    for batch in train_loader:\n","        real_data = batch[0] if dataset_choice == 'mnist' else batch\n","\n","        d_loss = train_discriminator_step(disc_model, gen_model, optim_d, loss_fn, real_data, device, params['z_size'], dataset_choice)\n","        g_loss = train_generator_step(disc_model, gen_model, optim_g, loss_fn, real_data.size(0), device, params['z_size'])\n","\n","        epoch_d_loss += d_loss\n","        epoch_g_loss += g_loss\n","\n","    avg_g_loss = epoch_g_loss / len(train_loader)\n","    avg_d_loss = epoch_d_loss / len(train_loader)\n","\n","    return avg_g_loss, avg_d_loss"],"metadata":{"id":"-_229uOWPFoH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def handle_epoch_logging(epoch, gen_model, device, params, dataset_choice, train_loader, components):\n","    \"\"\"Lida com o logging e salvamento de amostras no final de uma época.\"\"\"\n","    g_losses = components['g_losses']\n","    d_losses = components['d_losses']\n","    epoch_samples_mnist = components['epoch_samples_mnist']\n","    fixed_noise_mnist = components['fixed_noise_mnist']\n","\n","    if dataset_choice == 'two_moons':\n","        if epoch % 25 == 0 or epoch == 1:\n","            log_and_save_samples(epoch, gen_model, device, params, dataset_choice, train_loader)\n","\n","    elif dataset_choice == 'mnist':\n","        if epoch % 5 == 0 or epoch == 1 or epoch == params['num_epochs']:\n","            print(f\"Época {epoch}/{params['num_epochs']} | G Loss: {g_losses[-1]:.4f} | D Loss: {d_losses[-1]:.4f}\")\n","            gen_model.eval()\n","            with torch.no_grad():\n","                samples = gen_model(fixed_noise_mnist).cpu()\n","                epoch_samples_mnist.append({'epoch': epoch, 'samples': samples})\n","            gen_model.train()"],"metadata":{"id":"OLKsM5RDPNhj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def treinar_gan(gen_model, disc_model, train_loader, device, params, dataset_choice):\n","    \"\"\"Orquestra o processo de treinamento da GAN.\"\"\"\n","\n","    # 1. Inicialização\n","    components = setup_training_components(gen_model, disc_model, device, params, dataset_choice)\n","\n","    print(f\"Começo do treino para o dataset: {dataset_choice}\")\n","    for epoch in range(1, params['num_epochs'] + 1):\n","\n","        # 2. Treinamento de uma época\n","        avg_g_loss, avg_d_loss = train_one_epoch(\n","            gen_model, disc_model, train_loader, components['loss_fn'],\n","            components['optim_d'], components['optim_g'], device, params, dataset_choice\n","        )\n","\n","        components['g_losses'].append(avg_g_loss)\n","        components['d_losses'].append(avg_d_loss)\n","\n","        # 3. Logging da época\n","        handle_epoch_logging(epoch, gen_model, device, params, dataset_choice, train_loader, components)\n","\n","    print(\"Fim do treino.\")\n","    return components['g_losses'], components['d_losses'], components['epoch_samples_mnist']\n"],"metadata":{"id":"5ULKoYgZFTWy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Salvando, carregando e testando:"],"metadata":{"id":"gdOgx3jSNzFS"}},{"cell_type":"code","source":["def save_model(model, dataset_choice):\n","    \"\"\"Salva o modelo do gerador treinado num arquivo.\"\"\"\n","    model_path = f'files/{dataset_choice}_generator.pt'\n","    torch.jit.script(model).save(model_path)\n","    print(f\"\\nModelo final salvo em: {model_path}\")\n","    return model_path"],"metadata":{"id":"G7p9vXcAN1se"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_model(model_path, device):\n","    \"\"\"Carrega um modelo salvo e o configura para o modo de avaliação.\"\"\"\n","    loaded_model = torch.jit.load(model_path, map_location=device)\n","    loaded_model.eval()\n","    return loaded_model"],"metadata":{"id":"R7MagNBpN3qg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_load_test_model(model, device, params, dataset_choice, train_loader):\n","    \"\"\"Salva o modelo final, carrega de volta, e gera um plot de amostras finais.\"\"\"\n","    # 1. Salva o modelo\n","    model_path = save_model(model, dataset_choice)\n","\n","    # 2. Carrega o modelo\n","    loaded_model = load_model(model_path, device)\n","\n","    # 3. Gera e plota as amostras finais\n","    final_samples = generate_samples(loaded_model, device, params)\n","    plot_final_samples(final_samples, dataset_choice, train_loader)"],"metadata":{"id":"b_W9Wu4JN9Gc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Executando:"],"metadata":{"id":"BnrrwLHmQhr1"}},{"cell_type":"code","source":["# ==========================================================\n","# --- CONTROLE PRINCIPAL: Escolha 'two_moons' ou 'mnist' ---\n","dataset_choice = 'two_moons'\n","# ==========================================================\n","\n","# 1. Pega os hiperparâmetros corretos\n","params = get_hyperparameters(dataset_choice)\n","\n","# 2. Prepara os dados\n","train_loader = preparar_dados(dataset_choice, params['batch_size'])\n","\n","# 3. Cria os modelos corretos\n","gerador = get_generator(dataset_choice, params['z_size'], params['image_size']).to(device)\n","discriminador = get_discriminator(dataset_choice, params['image_size']).to(device)\n","\n","# 4. Treina a GAN\n","g_losses, d_losses, epoch_samples = treinar_gan(gerador, discriminador, train_loader, device, params, dataset_choice)\n","\n","# 5.Exibe os resultados\n","plot_losses(g_losses, d_losses)\n","\n","if dataset_choice == 'two_moons':\n","    plot_two_moons_evolution()\n","elif dataset_choice == 'mnist':\n","    plot_mnist_evolution(epoch_samples)\n","\n","save_load_test_model(gerador, device, params, dataset_choice, train_loader)"],"metadata":{"id":"whTSgR9SQkb9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchsummary import summary\n","\n","dataset_choice = 'mnist'\n","\n","params = get_hyperparameters(dataset_choice)\n","train_loader = preparar_dados(dataset_choice, params['batch_size'])\n","\n","gerador = get_generator(dataset_choice, params['z_size'], params['image_size']).to(device)\n","discriminador = get_discriminator(dataset_choice, params['image_size']).to(device)\n","\n","summary(gerador, input_size=(1, params['z_size']))\n","\n","summary(discriminador, input_size=(1, np.prod(params['image_size'])))"],"metadata":{"id":"EqDl7GThxyNq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Para o lab 6:"],"metadata":{"id":"XMuyXIrDjOJv"}},{"cell_type":"code","source":["# ==========================================================\n","# --- CONTROLE PRINCIPAL: Escolha 'two_moons' ou 'mnist' ---\n","dataset_choice = 'mnist'\n","# ==========================================================\n","\n","# 1. Pega os hiperparâmetros corretos\n","params = get_hyperparameters(dataset_choice)\n","\n","# 2. Prepara os dados\n","train_loader = preparar_dados(dataset_choice, params['batch_size'])\n","\n","# 3. Cria os modelos corretos\n","gerador = get_generator(dataset_choice, params['z_size'], params['image_size']).to(device)\n","discriminador = get_discriminator(dataset_choice, params['image_size']).to(device)\n","\n","# 4. Treina a GAN\n","g_losses, d_losses, epoch_samples = treinar_gan(gerador, discriminador, train_loader, device, params, dataset_choice)\n","\n","# 5.Exibe os resultados\n","plot_losses(g_losses, d_losses)\n","\n","if dataset_choice == 'two_moons':\n","    plot_two_moons_evolution()\n","elif dataset_choice == 'mnist':\n","    plot_mnist_evolution(epoch_samples)\n","\n","save_load_test_model(gerador, device, params, dataset_choice, train_loader)"],"metadata":{"id":"7c8w4kimiHNN"},"execution_count":null,"outputs":[]}]}