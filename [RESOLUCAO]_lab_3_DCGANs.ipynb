{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["u3mHuYgV5d1H","J-jgGUVOEO3x","CtvFIuowVcJ3","FLEjcIZDdbRn","_KjFwltldbAn","73sLgeiXsc0h"],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyOAVzFjKCr3vfuBo2Hl+Yr3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# IMD3004 - IA Generativa"],"metadata":{"id":"7IlJowSa4Y6t"}},{"cell_type":"markdown","source":["### Professor: Dr. Leonardo Enzo Brito da Silva"],"metadata":{"id":"M5edkneO4dGw"}},{"cell_type":"markdown","source":["### Aluno: João Antonio Costa Paiva Chagas"],"metadata":{"id":"nYOnHe-yZvEi"}},{"cell_type":"markdown","source":["## Tarefa:\n","\n","Utilize a base de dados de dígitos MNIST.\n","\n","1. Modifique a arquitetura do gerador base (reduzindo sua capacidade) mantendo o discriminador base.\n","\n","por exemplo\n","- removendo camadas\n","- reduzindo o número de kernels por camada\n","\n","2. Modifique a arquitetura do discriminador base (reduzindo sua capacidade) mantendo o gerador base.\n","\n","por exemplo:\n","- removendo camadas\n","- reduzindo o número de kernels por camada\n","\n","3. Varie as taxas de aprendizado do gerador e do discriminador de forma independente.\n","\n","4. Teste um otimizador adicional (ex.: SGD ou Adam).\n","\n","5. Realize a interpolação entre dois vetores latentes.\n","\n","\n","Entregáveis:\n","1. Notebook\n","2. Relatório pdf: **Reporte e comente os resultados no relatório.**"],"metadata":{"id":"SR7T2IbYZmsM"}},{"cell_type":"markdown","source":["### Importações:"],"metadata":{"id":"hSA-uH9HnDwG"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import os\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from torchvision import datasets"],"metadata":{"id":"_m30AxTg6l18"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ambiente"],"metadata":{"id":"NyvqaPRGSaH9"}},{"cell_type":"code","source":["if not os.path.exists('files'):\n","    os.makedirs('files')"],"metadata":{"id":"nJEAfvsISdp_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dados:"],"metadata":{"id":"DE4-1OsT5tgG"}},{"cell_type":"code","source":["def get_mnist_transform():\n","    return transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,))\n","    ])"],"metadata":{"id":"ENCj06DW-Umv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_mnist_dataset(transform):\n","    training_data = datasets.MNIST(\n","        root=\"data\",\n","        train=True,\n","        download=True,\n","        transform=transform,\n","    )\n","\n","    return training_data"],"metadata":{"id":"JgGgzwtB-XOP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dataloader(training_data, batch_size):\n","    train_dataloader = DataLoader(\n","        training_data,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=2,\n","        pin_memory=True\n","    )\n","\n","    return train_dataloader"],"metadata":{"id":"TzIAEIN1-ZkA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_mnist_data(batch_size):\n","    transform = get_mnist_transform()\n","    training_data = load_mnist_dataset(transform)\n","    return create_dataloader(training_data, batch_size)"],"metadata":{"id":"W0CALB-g9H-b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Plotando:"],"metadata":{"id":"WJAl5QHoKNe4"}},{"cell_type":"code","source":["# Define a função de gerar dados falsos de um vetores latentes aleatorios\n","def gerar_aleatorio(gerador, device, z_dim, n_images=20):\n","    gerador.eval()                  # Coloca o modelo em modo de avaliação (desativa dropout, batchnorm, etc.)\n","    z = torch.randn((n_images, z_dim), device=device)\n","    # Desativa o cálculo de gradientes para economizar memória e acelerar a execução\n","    with torch.no_grad():\n","      dados_falsos = modelo_gerador(z).detach().cpu().numpy()\n","    return dados_falsos"],"metadata":{"id":"T7RfuVHsL1KH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Função para plotar várias imagens em um grid\n","def plot_multiple_images(imagens):\n","    # Cria subplots (1 linha, -1 colunas)\n","    fig, axes = plt.subplots(1, len(imagens), figsize=(15, 2))\n","\n","    # Itera por cada subplot e mostra a imagem\n","    for ax, img in zip(axes, imagens):\n","        ax.imshow(img, cmap='gray')    # 1 = preto, 0 = branco\n","        ax.axis('off')                 # Remove ticks dos eixos\n","\n","    plt.subplots_adjust(wspace=0.1)    # ajusta o espacamento entre subplots\n","\n","    plt.show()"],"metadata":{"id":"xlKDyZ8UL2Do"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def interpolar_espaco_latente(gerador, z_dim, steps, device='cpu'):\n","\n","    # Gera dois vetores latentes aleatórios\n","    z1 = torch.randn((1, z_dim), device=device)\n","    z2 = torch.randn((1, z_dim), device=device)\n","\n","    gerador.eval()  # Coloca o gerador em modo de avaliação\n","\n","    alpha_valores = torch.linspace(0, 1, steps).to(device)  # Valores de interpolação entre 0 e 1\n","    imagens_interpoladas = []\n","\n","    for alpha in alpha_valores:\n","        # Interpola linearmente entre z1 e z2: z_interp = (1 - alpha) * z1 + alpha * z2 , alpha em [0, 1]\n","        z_interp = (1 - alpha) * z1 + alpha * z2\n","\n","        with torch.no_grad():  # Evita calcular gradientes (modo de inferência)\n","            imagem_gerada = gerador(z_interp.to(device)).cpu()\n","\n","        # Remove dimensões extras e converte para numpy\n","        imagens_interpoladas.append(imagem_gerada.squeeze().numpy())\n","\n","    return imagens_interpoladas"],"metadata":{"id":"kXpNzDg-sVcT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### DCGAN:"],"metadata":{"id":"B3zmdNza44fl"}},{"cell_type":"markdown","source":["#### Hiperparâmetros:"],"metadata":{"id":"3gPYkVnI5fRZ"}},{"cell_type":"code","source":["def get_hyperparameters(experiment_choice):\n","    \"\"\"\n","    Retorna um dicionário de hiperparâmetros baseado na escolha do experimento.\n","\n","    Convenção de Nomes:\n","    - Otimizadores: 'Ig' (Iguais), 'Ind1' (G=SGD, D=Adam), 'Ind2' (G=Adam, D=SGD)\n","    - Taxas de Apr.: 'Ig' (Iguais), 'Ind1' (G<D), 'Ind2' (G>D)\n","\n","    Exemplo: 'Ind1Ind2' -> G=SGD, D=Adam (Otimizadores Independentes 1) e G>D (LRs Independentes 2)\n","\n","    Choices Válidas:\n","    - 'IgIg': G/D Adam, LRs iguais\n","    - 'IgInd1': G/D Adam, LR G < D\n","    - 'IgInd2': G/D Adam, LR G > D\n","    - 'Ind1Ig': G=SGD/D=Adam, LRs iguais\n","    - 'Ind2Ig': G=Adam/D=SGD, LRs iguais\n","    - 'Ind1Ind1': G=SGD/D=Adam, LR G < D\n","    - 'Ind2Ind1': G=Adam/D=SGD, LR G < D\n","    - 'Ind1Ind2': G=SGD/D=Adam, LR G > D\n","    - 'Ind2Ind2': G=Adam/D=SGD, LR G > D\n","    \"\"\"\n","\n","    base_params = {\n","        'z_size': 100,\n","        'num_epochs': 50,\n","        'batch_size': 64\n","    }\n","\n","    if experiment_choice == 'IgIg':\n","        # Configuração com taxas de aprendizado iguais e otimizadores iguais\n","        exp_params = {\n","            'lr_g': 0.0002,\n","            'lr_d': 0.0002,\n","            'optimizer_g': 'Adam',\n","            'optimizer_d': 'Adam'\n","        }\n","    elif experiment_choice == 'IgInd1':\n","        # Teste com taxas de aprendizado independentes e otimizadores iguais\n","        print(\"Executando experimento com taxas de aprendizado diferentes.\")\n","        exp_params = {\n","            'lr_g': 0.0001,  # Gerador mais lento\n","            'lr_d': 0.0004,  # Discriminador mais rápido\n","            'optimizer_g': 'Adam',\n","            'optimizer_d': 'Adam'\n","        }\n","    elif experiment_choice == 'IgInd2':\n","        # Teste com taxas de aprendizado independentes e otimizadores iguais\n","        print(\"Executando experimento com taxas de aprendizado diferentes.\")\n","        exp_params = {\n","            'lr_g': 0.0004,  # Gerador mais rápido\n","            'lr_d': 0.0001,  # Discriminador mais lento\n","            'optimizer_g': 'Adam',\n","            'optimizer_d': 'Adam'\n","        }\n","    elif experiment_choice == 'Ind1Ig':\n","        # Configuração com taxas de aprendizado iguais e otimizadores independentes\n","        exp_params = {\n","            'lr_g': 0.0002,\n","            'lr_d': 0.0002,\n","            'optimizer_g': 'SGD',\n","            'optimizer_d': 'Adam'\n","        }\n","    elif experiment_choice == 'Ind2Ig':\n","        # Configuração com taxas de aprendizado iguais e otimizadores independentes\n","        exp_params = {\n","            'lr_g': 0.0002,\n","            'lr_d': 0.0002,\n","            'optimizer_g': 'Adam',\n","            'optimizer_d': 'SGD'\n","        }\n","    elif experiment_choice == 'Ind1Ind1':\n","        # Teste com taxas de aprendizado independentes e otimizadores independentes\n","        print(\"Executando experimento com taxas de aprendizado diferentes.\")\n","        exp_params = {\n","            'lr_g': 0.0001,  # Gerador mais lento\n","            'lr_d': 0.0004,  # Discriminador mais rápido\n","            'optimizer_g': 'SGD',\n","            'optimizer_d': 'Adam'\n","        }\n","    elif experiment_choice == 'Ind2Ind1':\n","        # Teste com taxas de aprendizado independentes e otimizadores independentes\n","        print(\"Executando experimento com taxas de aprendizado diferentes.\")\n","        exp_params = {\n","            'lr_g': 0.0001,  # Gerador mais lento\n","            'lr_d': 0.0004,  # Discriminador mais rápido\n","            'optimizer_g': 'Adam',\n","            'optimizer_d': 'SGD'\n","        }\n","    elif experiment_choice == 'Ind1Ind2':\n","        # Teste com taxas de aprendizado independentes e otimizadores independentes\n","        print(\"Executando experimento com taxas de aprendizado diferentes.\")\n","        exp_params = {\n","            'lr_g': 0.0004,  # Gerador mais rápido\n","            'lr_d': 0.0001,  # Discriminador mais lento\n","            'optimizer_g': 'SGD',\n","            'optimizer_d': 'Adam'\n","        }\n","    elif experiment_choice == 'Ind2Ind2':\n","        # Teste com taxas de aprendizado independentes e otimizadores independentes\n","        print(\"Executando experimento com taxas de aprendizado diferentes.\")\n","        exp_params = {\n","            'lr_g': 0.0004,  # Gerador mais rápido\n","            'lr_d': 0.0001,  # Discriminador mais lento\n","            'optimizer_g': 'Adam',\n","            'optimizer_d': 'SGD'\n","        }\n","    base_params.update(exp_params)\n","    return base_params"],"metadata":{"id":"tuql1kNXf-jD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Gerador:"],"metadata":{"id":"u3mHuYgV5d1H"}},{"cell_type":"markdown","source":["Gerador base:"],"metadata":{"id":"X1eFh3be3KwF"}},{"cell_type":"code","source":["class Gerador(nn.Module):\n","    def __init__(self, z_dim):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(z_dim, 7*7*256), # 128 para esse lab, 256 para o lab 6\n","            nn.Unflatten(dim=1, unflattened_size=(256, 7, 7)),\n","            nn.BatchNorm2d(256),\n","            nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1),\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(128),\n","            nn.ConvTranspose2d(128, 1, kernel_size=5, stride=2, padding=2, output_padding=1),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, z):\n","        return self.net(z)"],"metadata":{"id":"XB2b-Yvbd0LP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Gerador fraco:"],"metadata":{"id":"8azkAmkW3NNK"}},{"cell_type":"code","source":["class GeradorFraco(nn.Module):\n","    def __init__(self, z_dim):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            # De 128 para 64 canais\n","            nn.Linear(z_dim, 7*7*64),\n","            nn.Unflatten(dim=1, unflattened_size=(64, 7, 7)),\n","            nn.BatchNorm2d(64),\n","\n","            # De 128->64 para 64->32\n","            nn.ConvTranspose2d(64, 32, kernel_size=5, stride=2, padding=2, output_padding=1),\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(32),\n","\n","            # De 64->1 para 32->1\n","            nn.ConvTranspose2d(32, 1, kernel_size=5, stride=2, padding=2, output_padding=1),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, z):\n","        return self.net(z)"],"metadata":{"id":"pR6KHv9W3OZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Discriminador:"],"metadata":{"id":"00lSiR2vOHHK"}},{"cell_type":"markdown","source":["Discriminador base:"],"metadata":{"id":"d6XE6ko63s2z"}},{"cell_type":"code","source":["class Discriminador(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(negative_slope=0.2),\n","            nn.Dropout(p=0.4),\n","            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(negative_slope=0.2),\n","            nn.Dropout(p=0.4),\n","            nn.Flatten(),\n","            nn.Linear(7*7*128, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"SGkem4_chHMX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Discriminador fraco:"],"metadata":{"id":"Mng3KqMo3uO2"}},{"cell_type":"code","source":["class DiscriminadorFraco(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            # De 64 para 32 canais\n","            nn.Conv2d(1, 32, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(negative_slope=0.2),\n","            nn.Dropout(p=0.4),\n","            # De 128 para 64\n","            nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(negative_slope=0.2),\n","            nn.Dropout(p=0.4),\n","            nn.Flatten(),\n","            # De (7*7*128) para (7*7*64)\n","            nn.Linear(7*7*64, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"bl_P9vvm3vkC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Treinamento:"],"metadata":{"id":"EyUvfr3U8lxx"}},{"cell_type":"code","source":["def train_dcgan(dataloader, gerador, discriminador, loss_fn, opt_gerador, opt_discriminador, device, epoch, z_dim):\n","    gerador.train()         # Coloca o modelo em modo de treinamento (ativa dropout, batchnorm, etc., se houver)\n","    discriminador.train()   # Coloca o modelo em modo de treinamento (ativa dropout, batchnorm, etc., se houver)\n","\n","    size = len(dataloader.dataset)\n","\n","    for batch, (real_data, _) in enumerate(dataloader):\n","\n","        batch_size = real_data.shape[0]\n","        real_data = real_data.to(device)\n","\n","        # ========================================\n","        # Treinamento do DISCRIMINADOR\n","        # ========================================\n","\n","        # Gera rótulos para dados reais (1) e falsos (0)\n","        labels_reais = torch.ones((batch_size, 1), device=device)\n","        labels_falsos = torch.zeros((batch_size, 1), device=device)\n","\n","        # Gera dados falsos a partir de ruído aleatório (distribuicão normal)\n","        z = torch.randn((batch_size, z_dim), device=device)\n","        dados_falsos = gerador(z)\n","\n","        # Calcula a saída do discriminador para dados reais e falsos\n","        saida_reais = discriminador(real_data)\n","        saida_falsos = discriminador(dados_falsos.detach())  # detach() evita que os gradientes fluam para o gerador\n","\n","        # Calcula a perda do discriminador\n","        perda_reais = loss_fn(saida_reais, labels_reais)\n","        perda_falsos = loss_fn(saida_falsos, labels_falsos)\n","        perda_discriminador = perda_reais + perda_falsos\n","\n","        # Atualiza o discriminador\n","        opt_discriminador.zero_grad()\n","        perda_discriminador.backward()\n","        opt_discriminador.step()\n","\n","        # ========================================\n","        # Treinamento do GERADOR\n","        # ========================================\n","\n","        # Gera novos vetores latentes\n","        z = torch.randn((batch_size, z_dim), device=device)\n","        dados_falsos = gerador(z)\n","\n","        # Queremos que o discriminador pense que os dados falsos são reais\n","        saida_falsos = discriminador(dados_falsos)\n","        perda_gerador = loss_fn(saida_falsos, labels_reais)  # usamos labels_reais aqui!\n","\n","        # Atualiza o gerador\n","        opt_gerador.zero_grad()\n","        perda_gerador.backward()\n","        opt_gerador.step()\n","\n","        # ========================================\n","        # Log de progresso\n","        # ========================================\n","        if batch % 100 == 0 or batch == len(dataloader) - 1:\n","            print(f\"[Época {epoch:03d}] [Lote {batch:03d}/{len(dataloader)}] \"\n","                  f\"Perda D: {perda_discriminador.item():.4f} | Perda G: {perda_gerador.item():.4f}\")\n"],"metadata":{"id":"zKcnQwJA5Mol"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a função de gerar dados falsos de um vetor latente fixo\n","def gerar(gerador, device, z_dim=100):\n","    gerador.eval()                  # Coloca o modelo em modo de avaliação (desativa dropout, batchnorm, etc.)\n","    # Desativa o cálculo de gradientes para economizar memória e acelerar a execução\n","    with torch.no_grad():\n","      z = torch.zeros((1, z_dim), device=device)\n","      dados_falsos = gerador(z).detach().cpu().numpy().reshape(28,28)\n","    return dados_falsos"],"metadata":{"id":"adYHyKSV5e5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def training_loop(dataloader, gerador, discriminador, opt_gerador, opt_discriminador, device, z_dim, num_epochs, lr_gerador, lr_discriminador):\n","    evolução_dado_falso = []\n","    loss_fn = nn.BCELoss()\n","    if opt_gerador == 'Adam':\n","        opt_gerador = torch.optim.Adam(gerador.parameters(), lr=lr_gerador, betas=(0.5, 0.999))\n","    elif opt_gerador == 'SGD':\n","        opt_gerador = torch.optim.SGD(gerador.parameters(), lr=lr_gerador, momentum=0.9)\n","\n","    if opt_discriminador == 'Adam':\n","        opt_discriminador = torch.optim.Adam(discriminador.parameters(), lr=lr_discriminador, betas=(0.5, 0.999))\n","    elif opt_discriminador == 'SGD':\n","        opt_discriminador = torch.optim.SGD(discriminador.parameters(), lr=lr_discriminador, momentum=0.9)\n","\n","    for epoca in range(1, num_epochs + 1):\n","        train_dcgan(\n","            dataloader=dataloader,\n","            gerador=modelo_gerador,\n","            discriminador=modelo_discriminador,\n","            loss_fn=loss_fn,\n","            opt_gerador=opt_gerador,\n","            opt_discriminador=opt_discriminador,\n","            device=device,\n","            epoch=epoca,  # Pass the current epoch number\n","            z_dim=z_dim\n","        )\n","        if epoca % 5 == 0 or epoca == 1 or epoca == num_epochs:\n","          evolução_dado_falso.append(gerar(gerador=modelo_gerador, device=device, z_dim=z_dim))\n","\n","    return evolução_dado_falso"],"metadata":{"id":"1pu6TexTIZe-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Salvando, carregando:"],"metadata":{"id":"gdOgx3jSNzFS"}},{"cell_type":"code","source":["def save_model(model, name):\n","    \"\"\"Salva o modelo do gerador treinado num arquivo.\"\"\"\n","    model_path = f'files/mnist_{name}_conv_dcgan.pt'\n","    torch.jit.script(model).save(model_path)\n","    print(f\"\\nModelo final salvo em: {model_path}\")\n","    return model_path"],"metadata":{"id":"xwSBNTTp4dsr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_model(model_path, device):\n","    \"\"\"Carrega um modelo salvo e o configura para o modo de avaliação.\"\"\"\n","    loaded_model = torch.jit.load(model_path, map_location=device)\n","    loaded_model.eval()\n","    return loaded_model"],"metadata":{"id":"K-nAROF5tDU7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Executando:"],"metadata":{"id":"BnrrwLHmQhr1"}},{"cell_type":"markdown","source":["#### 1:"],"metadata":{"id":"J-jgGUVOEO3x"}},{"cell_type":"code","source":["# Pega os hiperparâmetros (otimizadores iguais, taxas de aprendizado iguais)\n","params = get_hyperparameters('IgIg')\n","\n","# Prepara os dados\n","train_loader = prepare_mnist_data(params['batch_size'])\n","\n","# Cria os modelos de gerador e discriminador\n","modelo_gerador = GeradorFraco(params['z_size'])\n","modelo_discriminador = Discriminador()\n","\n","device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n","modelo_gerador.to(device)\n","modelo_discriminador.to(device)\n","\n","# Treinando\n","evolucao = training_loop(\n","    train_loader,\n","    modelo_gerador,\n","    modelo_discriminador,\n","    params['optimizer_g'],\n","    params['optimizer_d'],\n","    device,\n","    params['z_size'],\n","    params['num_epochs'],\n","    params['lr_g'],\n","    params['lr_d']\n","    )\n","\n","# Desenhando\n","plot_multiple_images(evolucao)\n","\n","# Salvando\n","save_model(modelo_gerador, 'weaker_generator')"],"metadata":{"id":"c1OptuUHEP8S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2:"],"metadata":{"id":"CtvFIuowVcJ3"}},{"cell_type":"code","source":["# Pega os hiperparâmetros (otimizadores iguais, taxas de aprendizado iguais)\n","params = get_hyperparameters('IgIg')\n","\n","# Prepara os dados\n","train_loader = prepare_mnist_data(params['batch_size'])\n","\n","# Cria os modelos de gerador e discriminador\n","modelo_gerador = Gerador(params['z_size'])\n","modelo_discriminador = DiscriminadorFraco()\n","\n","device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n","modelo_gerador.to(device)\n","modelo_discriminador.to(device)\n","\n","# Treinando\n","evolucao = training_loop(\n","    train_loader,\n","    modelo_gerador,\n","    modelo_discriminador,\n","    params['optimizer_g'],\n","    params['optimizer_d'],\n","    device,\n","    params['z_size'],\n","    params['num_epochs'],\n","    params['lr_g'],\n","    params['lr_d']\n","    )\n","\n","# Desenhando\n","plot_multiple_images(evolucao)\n","\n","# Salvando\n","save_model(modelo_gerador, 'weaker_discriminator')"],"metadata":{"id":"a5rFmDb-Vb6t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3:"],"metadata":{"id":"FLEjcIZDdbRn"}},{"cell_type":"code","source":["# Pega os hiperparâmetros (Gerador mais lento, discriminador mais rápido, otimizadores iguais)\n","params = get_hyperparameters('IgInd1')\n","\n","# Prepara os dados\n","train_loader = prepare_mnist_data(params['batch_size'])\n","\n","# Cria os modelos de gerador e discriminador\n","modelo_gerador = Gerador(params['z_size'])\n","modelo_discriminador = Discriminador()\n","\n","device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n","modelo_gerador.to(device)\n","modelo_discriminador.to(device)\n","\n","# Treinando\n","evolucao = training_loop(\n","    train_loader,\n","    modelo_gerador,\n","    modelo_discriminador,\n","    params['optimizer_g'],\n","    params['optimizer_d'],\n","    device,\n","    params['z_size'],\n","    params['num_epochs'],\n","    params['lr_g'],\n","    params['lr_d']\n","    )\n","\n","# Desenhando\n","plot_multiple_images(evolucao)\n","\n","# Salvando\n","save_model(modelo_gerador, 'slower_generator_quicker_discriminator')"],"metadata":{"id":"hrS5YDoMe0Ws"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pega os hiperparâmetros (Gerador mais rápido, discriminador mais lento, otimizadores iguais)\n","params = get_hyperparameters('IgInd2')\n","\n","# Prepara os dados\n","train_loader = prepare_mnist_data(params['batch_size'])\n","\n","# Cria os modelos de gerador e discriminador\n","modelo_gerador = Gerador(params['z_size'])\n","modelo_discriminador = Discriminador()\n","\n","device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n","modelo_gerador.to(device)\n","modelo_discriminador.to(device)\n","\n","# Treinando\n","evolucao = training_loop(\n","    train_loader,\n","    modelo_gerador,\n","    modelo_discriminador,\n","    params['optimizer_g'],\n","    params['optimizer_d'],\n","    device,\n","    params['z_size'],\n","    params['num_epochs'],\n","    params['lr_g'],\n","    params['lr_d']\n","    )\n","\n","# Desenhando\n","plot_multiple_images(evolucao)\n","\n","# Salvando\n","save_model(modelo_gerador, 'quicker_generator_slower_discriminator')"],"metadata":{"id":"tK79MIkSfCaU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4:"],"metadata":{"id":"_KjFwltldbAn"}},{"cell_type":"code","source":["# Pega os hiperparâmetros (Gerador com otimizador SGD, discriminador com otimizador Adam, taxas de aprendizado iguais)\n","params = get_hyperparameters('Ind1Ig')\n","\n","# Prepara os dados\n","train_loader = prepare_mnist_data(params['batch_size'])\n","\n","# Cria os modelos de gerador e discriminador\n","modelo_gerador = Gerador(params['z_size'])\n","modelo_discriminador = Discriminador()\n","\n","device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n","modelo_gerador.to(device)\n","modelo_discriminador.to(device)\n","\n","# Treinando\n","evolucao = training_loop(\n","    train_loader,\n","    modelo_gerador,\n","    modelo_discriminador,\n","    params['optimizer_g'],\n","    params['optimizer_d'],\n","    device,\n","    params['z_size'],\n","    params['num_epochs'],\n","    params['lr_g'],\n","    params['lr_d']\n","    )\n","\n","# Desenhando\n","plot_multiple_images(evolucao)\n","\n","# Salvando\n","save_model(modelo_gerador, 'sgd_generator_adam_discriminator')"],"metadata":{"id":"l1JxayvSfZD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Pega os hiperparâmetros (Gerador com otimizador Adam, discriminador com otimizador SGD, taxas de aprendizado iguais)\n","params = get_hyperparameters('Ind2Ig')\n","\n","# Prepara os dados\n","train_loader = prepare_mnist_data(params['batch_size'])\n","\n","# Cria os modelos de gerador e discriminador\n","modelo_gerador = Gerador(params['z_size'])\n","modelo_discriminador = Discriminador()\n","\n","device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n","modelo_gerador.to(device)\n","modelo_discriminador.to(device)\n","\n","# Treinando\n","evolucao = training_loop(\n","    train_loader,\n","    modelo_gerador,\n","    modelo_discriminador,\n","    params['optimizer_g'],\n","    params['optimizer_d'],\n","    device,\n","    params['z_size'],\n","    params['num_epochs'],\n","    params['lr_g'],\n","    params['lr_d']\n","    )\n","\n","# Desenhando\n","plot_multiple_images(evolucao)\n","\n","# Salvando\n","save_model(modelo_gerador, 'adam_generator_sgd_discriminator')"],"metadata":{"id":"ET9n6YmxfbUy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 5:"],"metadata":{"id":"73sLgeiXsc0h"}},{"cell_type":"code","source":["base_gen = load_model('files/mnist_base_conv_dcgan.pt', device)\n","imagens_base_generator_model = interpolar_espaco_latente(base_gen, 100, 20, device)\n","plot_multiple_images(imagens_base_generator_model)"],"metadata":{"id":"BKgMIgs7tqx5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weaker_gen = load_model('files/mnist_weaker_generator_conv_dcgan.pt', device)\n","imagens_weaker_generator_model = interpolar_espaco_latente(weaker_gen, 100, 20, device)\n","plot_multiple_images(imagens_weaker_generator_model)"],"metadata":{"id":"NXC-pgbIseoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weaker_disc = load_model('files/mnist_weaker_discriminator_conv_dcgan.pt', device)\n","imagens_weaker_discriminator_model = interpolar_espaco_latente(weaker_disc, 100, 20, device)\n","plot_multiple_images(imagens_weaker_discriminator_model)"],"metadata":{"id":"XvUuBI0btW0N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["slow_quick = load_model('files/mnist_slower_generator_quicker_discriminator_conv_dcgan.pt', device)\n","imagens_slow_quick_model = interpolar_espaco_latente(slow_quick, 100, 20, device)\n","plot_multiple_images(imagens_slow_quick_model)"],"metadata":{"id":"wELu1MANtdBo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["quick_slow = load_model('files/mnist_quicker_generator_slower_discriminator_conv_dcgan.pt', device)\n","imagens_quick_slow_model = interpolar_espaco_latente(quick_slow, 100, 20, device)\n","plot_multiple_images(imagens_quick_slow_model)"],"metadata":{"id":"1qZbfanst30u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sgd_adam = load_model('files/mnist_sgd_generator_adam_discriminator_conv_dcgan.pt', device)\n","imagens_sgd_adam_model = interpolar_espaco_latente(sgd_adam, 100, 20, device)\n","plot_multiple_images(imagens_sgd_adam_model)"],"metadata":{"id":"wcu3NzYpt83T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["adam_sgd = load_model('files/mnist_adam_generator_sgd_discriminator_conv_dcgan.pt', device)\n","imagens_adam_sgd_model = interpolar_espaco_latente(adam_sgd, 100, 20, device)\n","plot_multiple_images(imagens_adam_sgd_model)"],"metadata":{"id":"fdUA_4PNuE3Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Para o lab 6:"],"metadata":{"id":"6carBUBXVMye"}},{"cell_type":"code","source":["# Pega os hiperparâmetros\n","params = get_hyperparameters('IgIg')\n","\n","# Prepara os dados\n","train_loader = prepare_mnist_data(params['batch_size'])\n","\n","# Cria os modelos de gerador e discriminador\n","modelo_gerador = Gerador(params['z_size'])\n","modelo_discriminador = Discriminador()\n","\n","device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n","modelo_gerador.to(device)\n","modelo_discriminador.to(device)\n","\n","# Treinando\n","evolucao = training_loop(\n","    train_loader,\n","    modelo_gerador,\n","    modelo_discriminador,\n","    params['optimizer_g'],\n","    params['optimizer_d'],\n","    device,\n","    params['z_size'],\n","    params['num_epochs'],\n","    params['lr_g'],\n","    params['lr_d']\n","    )\n","\n","# Desenhando\n","plot_multiple_images(evolucao)\n","\n","# Salvando\n","save_model(modelo_gerador, 'base')"],"metadata":{"id":"wzlKUc9uVMER"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchsummary import summary\n","\n","params = get_hyperparameters('IgIg')\n","train_loader = prepare_mnist_data(params['batch_size'])\n","\n","modelo_gerador = Gerador(params['z_size'])\n","modelo_discriminador = Discriminador()\n","\n","summary(modelo_gerador, input_size=(params['z_size'],))\n","summary(modelo_discriminador, input_size=(1, 28, 28))"],"metadata":{"id":"Hseaf2dR12Sk"},"execution_count":null,"outputs":[]}]}