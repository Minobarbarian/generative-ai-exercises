{"cells":[{"cell_type":"markdown","metadata":{"id":"9af74Nwj3BIy"},"source":["# IMD3004 - IA Generativa"]},{"cell_type":"markdown","metadata":{"id":"_pwt8WA-3EGx"},"source":["### Professor: Dr. Leonardo Enzo Brito da Silva"]},{"cell_type":"markdown","metadata":{"id":"ZrrRZuYa3FxY"},"source":["### Aluno: Jo√£o Antonio Costa Paiva Chagas"]},{"cell_type":"markdown","source":["# Laborat√≥rio 9: Variational Autoencoders"],"metadata":{"id":"enUqx0TWm_IV"}},{"cell_type":"markdown","metadata":{"id":"tpct25jB6dGF"},"source":["C√≥digo adaptado de:\n","\n","[1] D. Foster, Generative Deep Learning: Teaching Machines to Paint, Write, Compose, and Play, Second Edition, O'Reilly, 2023.\n","\n","[2] A. G√©ron, Hands-On Machine Learning with Scikit-Learning, Keras & Tensorflow, Third Edition, O'Reilly, 2022."]},{"cell_type":"markdown","metadata":{"id":"Nkjrhj9MXyeP"},"source":["## Importa√ß√µes e configura√ß√µes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xhH3ge406diO"},"outputs":[],"source":["!pip install torchinfo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fUETwq6A7Z7n"},"outputs":[],"source":["from __future__ import annotations                    # Permite anota√ß√µes de tipos futuristas (self-referenciais)\n","from tqdm.auto import tqdm                            # Barra de progresso visual para loops (compat√≠vel com notebooks e terminal)\n","import matplotlib.pyplot as plt                       # Biblioteca para gera√ß√£o de gr√°ficos e visualiza√ß√µes\n","import numpy as np                                    # Biblioteca para opera√ß√µes num√©ricas vetorizadas\n","import os\n","import torch                                          # Biblioteca PyTorch\n","import torch.nn as nn                                 # Subm√≥dulo com classes de camadas neurais\n","import torch.nn.functional as F                       # Subm√≥dulo com fun√ß√µes √∫teis (ativa√ß√£o, perdas, etc.)\n","from scipy.stats import norm                          # Fun√ß√µes estat√≠sticas (ex.: percentis e PDF da normal)\n","from torch.utils.data import DataLoader               # Gerenciador de mini-lotes de dados (facilita o treinamento)\n","from torchvision import datasets, transforms          # Conjuntos de dados e transforma√ß√µes de imagem do PyTorch\n","from torchinfo import summary                         # Sum√°rio detalhado de modelos (tamanhos, par√¢metros, shapes)\n","from typing import Optional                           # Para salvar os plots..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RzAchqie7edo"},"outputs":[],"source":["# Define o dispositivo de hardware para execu√ß√£o: usa acelerador (GPU/TPU) se dispon√≠vel; caso contr√°rio, usa a CPU\n","DISPOSITIVO = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Exibe qual dispositivo est√° sendo utilizado\n","print(f\"Usando {DISPOSITIVO}.\")"]},{"cell_type":"markdown","source":["## Armazenamento"],"metadata":{"id":"neTRNPfQnTy2"}},{"cell_type":"code","source":["output_dir = \"resultados_plots\"\n","os.makedirs(output_dir, exist_ok=True)"],"metadata":{"id":"mfX56zH4nVhu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TloWAxbJXyeR"},"source":["## Hiperpar√¢metros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1V9GKS3jXyeR"},"outputs":[],"source":["EPOCAS_CONV            = 10                                                     # N√∫mero total de √©pocas de treinamento\n","TAMANHO_LOTE_CONV      = 128                                                    # Tamanho do mini-lote (batch size)\n","DIMENSAO_LATENTE_CONV  = 2                                                      # Dimensionalidade do espa√ßo latente z"]},{"cell_type":"markdown","metadata":{"id":"Y2m13yMw7o8Q"},"source":["## Dados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EONNCGmt7nj5"},"outputs":[],"source":["def carregar_dados_mnist(transformacao_imagem, tamanho_lote):\n","\n","    # Carrega conjunto de treinamento (baixado automaticamente se n√£o existir)\n","    train_data = datasets.MNIST(\n","        root=\"dados\",\n","        train=True,\n","        transform=transformacao_imagem,\n","        download=True,\n","    )\n","\n","    # Carrega conjunto de teste (baixado automaticamente se n√£o existir)\n","    test_data = datasets.MNIST(\n","        root=\"dados\",\n","        train=False,\n","        transform=transformacao_imagem,\n","        download=True,\n","    )\n","\n","    # Cria DataLoaders (embaralha apenas o conjunto de treinamento)\n","    train_dl = DataLoader(train_data, batch_size=tamanho_lote, shuffle=True)\n","    test_dl = DataLoader(test_data, batch_size=tamanho_lote, shuffle=False)\n","\n","    return train_dl, test_dl, len(train_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVM8u9bgXyeS"},"outputs":[],"source":["# Define a transforma√ß√£o das imagens (converte para tensor normalizado em [0,1])\n","transformacao_densa = transforms.ToTensor()\n","\n","# Carrega os conjuntos de treinamento e teste do MNIST com o tamanho de lote definido\n","train_dl, test_dl, _ = carregar_dados_mnist(transformacao_imagem=transformacao_densa, tamanho_lote=TAMANHO_LOTE_CONV)"]},{"cell_type":"markdown","source":["## Autoencoder variacional convolucional"],"metadata":{"id":"axZOTngypV2r"}},{"cell_type":"code","source":["class CamadaAmostragemLatente(nn.Module):\n","    \"\"\"Implementa a amostragem reparametrizada z = Œº + œÉ¬∑Œµ com Œµ ~ N(0,I).\"\"\"\n","\n","    def forward(self, media, log_variancia):\n","        \"\"\"Gera uma amostra z a partir dos par√¢metros da distribui√ß√£o Gaussiana.\"\"\"\n","        ruido_gaussiano = torch.randn_like(log_variancia)               # Œµ ~ N(0,¬†ùêà)\n","        desvio_padrao   = torch.exp(0.5 * log_variancia)                # œÉ = e^(logœÉ¬≤‚ÄØ/‚ÄØ2)\n","        vetor_latente   = media + desvio_padrao * ruido_gaussiano       # z = Œº¬†+¬†œÉ¬∑Œµ\n","        return vetor_latente"],"metadata":{"id":"CQgsku16rf44"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CodificadorConvolucional(nn.Module):\n","    \"\"\"Codificador convolucional para imagens 28x28.\"\"\"\n","\n","    def __init__(self, dimensao_latente):\n","        super().__init__()\n","\n","        self.bloco_convolucional = nn.Sequential(\n","            # Entrada: (B, 1, 28, 28)\n","            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),               # Sa√≠da: (B, 32, 14, 14)\n","            nn.ReLU(),\n","            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),              # Sa√≠da: (B, 64, 7, 7)\n","            nn.ReLU(),\n","            nn.Flatten()                                                        # Sa√≠da: (B, 3136)\n","        )\n","\n","        self.camada_media = nn.Linear(64 * 7 * 7, dimensao_latente)             # Camada linear para m√©dia Œº\n","        self.camada_log_variancia = nn.Linear(64 * 7 * 7, dimensao_latente)     # Camada linear para log-vari√¢ncia logœÉ¬≤\n","        self.camada_amostragem = CamadaAmostragemLatente()                      # Reparametriza√ß√£o: z = Œº + œÉ¬∑Œµ\n","\n","    def forward(self, imagens):\n","        \"\"\"Propaga a imagem e retorna (Œº, logœÉ¬≤, z).\"\"\"\n","        x = self.bloco_convolucional(imagens)                               # Extrai e achata as caracter√≠sticas convolucionais\n","        media = self.camada_media(x)                                        # Vetor de m√©dias (Œº)\n","        log_variancia = self.camada_log_variancia(x)                        # Vetor de log-vari√¢ncias (logœÉ¬≤)\n","        vetor_latente = self.camada_amostragem(media, log_variancia)        # Amostra reparametrizada (z = Œº + œÉ¬∑Œµ)\n","        return media, log_variancia, vetor_latente"],"metadata":{"id":"ZZOUQcRBuo5d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DecodificadorConvolucional(nn.Module):\n","    \"\"\"Decodificador convolucional.\"\"\"\n","\n","    def __init__(self, dimensao_latente):\n","        super().__init__()\n","\n","        self.camada_densa = nn.Linear(dimensao_latente, 64 * 7 * 7)             # Mapeando o vetor latente de volta √† dimens√£o convolucional\n","\n","        self.bloco_convolucional = nn.Sequential(\n","            # Entrada: (B, 64, 7, 7)\n","            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # Sa√≠da: (B, 32, 14, 14)\n","            nn.ReLU(),\n","            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),   # Sa√≠da: (B, 1, 28, 28)\n","            nn.Sigmoid()                                                                       # Sa√≠da ‚àà (0,1)\n","        )\n","\n","    def forward(self, vetor_latente):\n","        \"\"\"Reconstr√≥i a imagem a partir do vetor latente z.\"\"\"\n","        x = self.camada_densa(vetor_latente)                                # Passa pelo primeiro bloco linear\n","        x = x.view(-1, 64, 7, 7)                                            # Reformata para o formato convolucional\n","        reconstrucao = self.bloco_convolucional(x)                          # Passa pelo pipeline convolucional\n","        return reconstrucao"],"metadata":{"id":"cJiTnZy1v6aA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AutoencoderVariacional(nn.Module):\n","    \"\"\"Agrupa codificador e decodificador e calcula a fun√ß√£o de perda MSE + Œ≤¬∑KL.\"\"\"\n","\n","    def __init__(self, codificador, decodificador):\n","        super().__init__()\n","        self.codificador    = codificador                                   # Rede que gera (Œº, logœÉ¬≤, z) a partir de x\n","        self.decodificador  = decodificador                                 # Rede que reconstr√≥i x a partir de z\n","\n","    def forward(self, imagens):\n","        \"\"\"Codifica as imagens, amostra z e reconstr√≥i as entradas.\"\"\"\n","        media, log_variancia, vetor_latente = self.codificador(imagens)     # Passo 1: codifica√ß√£o x ‚Üí (Œº, logœÉ¬≤, z)\n","        reconstrucao = self.decodificador(vetor_latente)                    # Passo 2: decodifica√ß√£o (z ‚Üí xÃÇ)\n","        return reconstrucao, media, log_variancia\n","\n","    @staticmethod\n","    def perda_mse_kl(reconstrucao, alvo, media, log_variancia, beta=1.0):\n","        \"\"\"Calcula a perda total: erro de reconstru√ß√£o (MSE) + regulariza√ß√£o (Œ≤¬∑KL).\"\"\"\n","        mse = F.mse_loss(reconstrucao, alvo, reduction=\"mean\")                                  # Erro de reconstru√ß√£o entre imagem original e reconstru√≠da\n","        kl = -0.5 * torch.sum(1 + log_variancia - media.pow(2) - log_variancia.exp(), dim=1)    # Termo KL: mede o afastamento entre q(z|x) = N(Œº,œÉ¬≤) (aprendida pelo codificador) e a distribui√ß√£o a priori p(z)=N(0,1) (assumida na modelagem)\n","        kl = kl.mean() / (alvo.size(2) * alvo.size(3))                                          # Normaliza por pixel (HxW) para manter mesma escala do MSE\n","        perda_total = mse + beta * kl                                                           # Combina termos: total = MSE + Œ≤¬∑KL\n","        return perda_total, mse.detach(), kl.detach()                                           # Detach: impede retropropaga√ß√£o nos logs"],"metadata":{"id":"wWbMtsqfwqNi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OOXCWm0y9Sff"},"source":["## Fun√ß√µes auxiliares"]},{"cell_type":"code","source":["def treinar_vae(modelo, carregador_treino, epocas, otimizador, beta, nome_tag):\n","\n","    tamanho_conjunto = len(carregador_treino.dataset)                                   # N√∫mero total de amostras no conjunto de treinamento\n","    historico_perda, historico_mse, historico_kl = [], [], []                           # Listas para armazenar o hist√≥rico de m√©tricas por √©poca\n","    progress_bar = tqdm(range(1, epocas + 1), desc=f\"[{nome_tag}] √âpocas\", ncols=100)   # Barra de progresso visual para acompanhar o treinamento\n","\n","    # Loop principal sobre as √©pocas\n","    for _ in progress_bar:\n","        modelo.train()                                       # Ativa modo de treinamento (dropout, BN, etc.)\n","        soma_perda = 0.0                                     # Acumulador de perda total\n","        soma_mse = 0.0                                       # Acumulador do erro de reconstru√ß√£o\n","        soma_kl = 0.0                                        # Acumulador do termo de regulariza√ß√£o KL\n","\n","        # Loop interno sobre os mini-lotes de treinamento\n","        for imagens, _ in carregador_treino:\n","            imagens = imagens.to(DISPOSITIVO)                                                                           # Move o lote para GPU ou CPU\n","            otimizador.zero_grad()                                                                                      # Zera gradientes acumulados\n","            reconstrucao, media, log_variancia = modelo(imagens)                                                        # Forward pass: x ‚Üí (Œº, logœÉ¬≤, z) ‚Üí xÃÇ\n","            perda, mse, kl = AutoencoderVariacional.perda_mse_kl(reconstrucao, imagens, media, log_variancia, beta)     # Calcula perda total e seus componentes\n","            perda.backward()                                                                                            # Retropropaga os gradientes\n","            otimizador.step()                                                                                           # Atualiza os par√¢metros da rede\n","\n","            # Acumula perdas ponderadas pelo tamanho do mini-lote\n","            soma_perda += perda.item() * imagens.size(0)\n","            soma_mse   += mse.item() * imagens.size(0)\n","            soma_kl    += kl.item() * imagens.size(0)\n","\n","        # Calcula m√©dias ponderadas das m√©tricas por √©poca\n","        perda_media = soma_perda / tamanho_conjunto\n","        mse_media   = soma_mse / tamanho_conjunto\n","        kl_media    = soma_kl / tamanho_conjunto\n","\n","        # Armazena hist√≥rico\n","        historico_perda.append(perda_media)\n","        historico_mse.append(mse_media)\n","        historico_kl.append(kl_media)\n","\n","        # Atualiza a barra de progresso com as m√©tricas atuais\n","        progress_bar.set_postfix({\n","            \"Perda\": f\"{perda_media:.5f}\",\n","            \"MSE\": f\"{mse_media:.5f}\",\n","            \"KL\": f\"{kl_media:.5f}\"\n","        })\n","\n","    # Retorna as curvas de perda, MSE e KL por √©poca\n","    return historico_perda, historico_mse, historico_kl"],"metadata":{"id":"Jvz2sNn13xVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def curvas_de_treinamento(loss_hist, mse_hist, kl_hist, save_path: Optional[str] = None):\n","    \"\"\"Plota as curvas de perda, MSE e KL ao longo das √©pocas.\"\"\"\n","    fig = plt.figure()                              # Cria a figura e define o tamanho\n","    plt.plot(loss_hist, label=\"Fun√ß√£o de perda\")    # Curva da perda total\n","    plt.plot(mse_hist, label=\"MSE\")                 # Curva do erro de reconstru√ß√£o\n","    plt.plot(kl_hist, label=\"KL\")                   # Curva do termo de regulariza√ß√£o\n","    plt.xlabel(\"√âpoca\")                             # Define o r√≥tulo do eixo X\n","    plt.legend()                                    # Exibe a legenda das curvas\n","    plt.grid(True)                                  # Adiciona grade ao gr√°fico\n","    plt.tight_layout()                              # Ajusta margens automaticamente\n","\n","    if save_path:\n","        directory = os.path.dirname(save_path)\n","        if directory:\n","            os.makedirs(directory, exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","    else:\n","        plt.show()                                      # Exibe o gr√°fico na tela"],"metadata":{"id":"4YVD3RXZqYv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UrWjVZYIXyeV"},"outputs":[],"source":["def mostrar_reconstrucoes(modelo, carregador_teste, quantidade_imagens, save_path: Optional[str] = None):\n","    \"\"\"Exibe imagens originais e respectivas reconstru√ß√µes lado a lado.\"\"\"\n","\n","    modelo.eval()                                          # Coloca o modelo em modo de avalia√ß√£o (desativa dropout, BN, etc.)\n","    imagens, _ = next(iter(carregador_teste))              # Obt√©m um √∫nico mini-lote do conjunto de teste\n","    imagens = imagens.to(DISPOSITIVO)[:quantidade_imagens] # Seleciona as N primeiras imagens e move para GPU/CPU\n","\n","    with torch.no_grad():                                  # Desativa o c√°lculo de gradientes\n","        reconstrucoes, _, _ = modelo(imagens)              # Passa as imagens pelo VAE ‚Üí obt√©m reconstru√ß√µes\n","\n","    fig = plt.figure(figsize=(quantidade_imagens * 1.5, 3))      # Define tamanho da figura de forma proporcional ao n√∫mero de imagens\n","\n","    for indice in range(quantidade_imagens):\n","\n","        # Linha superior: imagens originais\n","        plt.subplot(2, quantidade_imagens, indice + 1)\n","        plt.imshow(imagens[indice].cpu().squeeze(), cmap=\"binary\")          # Exibe imagem real (convertida para CPU)\n","        plt.axis(\"off\")                                                     # Remove eixos\n","\n","        # Linha inferior: imagens reconstru√≠das\n","        plt.subplot(2, quantidade_imagens, quantidade_imagens + indice + 1)\n","        plt.imshow(reconstrucoes[indice].cpu().squeeze(), cmap=\"binary\")    # Exibe reconstru√ß√£o correspondente\n","        plt.axis(\"off\")                                                     # Remove eixos\n","\n","    plt.tight_layout()                                     # Ajusta espa√ßamento automaticamente\n","\n","    if save_path:\n","        directory = os.path.dirname(save_path)\n","        if directory:\n","            os.makedirs(directory, exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","    else:\n","        plt.show()                                             # Exibe a figura"]},{"cell_type":"code","source":["def visualizar_espaco_latente(modelo, carregador_dados, save_path: Optional[str] = None):\n","    \"\"\"Projeta os vetores de m√©dias Œº no espa√ßo latente 2D, colorindo cada ponto pela classe.\"\"\"\n","\n","    modelo.eval()                                         # Coloca o modelo em modo de avalia√ß√£o (sem dropout, BN, etc.)\n","    vetores_latentes = []                                 # Lista para armazenar os vetores Œº de cada amostra\n","    rotulos = []                                          # Lista para armazenar os r√≥tulos correspondentes\n","\n","    with torch.no_grad():                                 # Desativa o c√°lculo de gradientes\n","\n","        for imagens, y in carregador_dados:               # Itera sobre todo o conjunto de dados\n","            imagens = imagens.to(DISPOSITIVO)             # Move lote para GPU/CPU\n","            media, _, _ = modelo.codificador(imagens)     # Extrai o vetor Œº de cada imagem\n","            vetores_latentes.append(media.cpu().numpy())  # Move para CPU e converte em numpy\n","            rotulos.append(y.numpy())                     # Armazena r√≥tulos das classes\n","\n","    # Concatena todos os vetores Œº e r√≥tulos em arrays √∫nicos\n","    pontos_z = np.concatenate(vetores_latentes)\n","    classes  = np.concatenate(rotulos)\n","\n","    fig = plt.figure(figsize=(8, 6))                                                                      # Define o tamanho da figura\n","    grafico = plt.scatter(pontos_z[:, 0], pontos_z[:, 1], c=classes, cmap=\"tab10\", s=10, alpha=0.7) # Cria o gr√°fico de dispers√£o dos pontos latentes coloridos por classe\n","    plt.colorbar(grafico, ticks=range(10), label=\"Classe\")                                          # Adiciona barra de cores indicando as classes\n","    plt.title(r\"Proje√ß√£o de $\\mu$ no espa√ßo latente (2D)\")                                          # T√≠tulo do gr√°fico\n","    plt.xlabel(\"z[0]\")                                                                              # Eixo horizontal: primeira dimens√£o latente\n","    plt.ylabel(\"z[1]\")                                                                              # Eixo vertical: segunda dimens√£o latente\n","    plt.grid(True)                                                                                  # Adiciona grade para melhor visualiza√ß√£o\n","    plt.tight_layout()                                                                              # Ajusta margens automaticamente\n","\n","    if save_path:\n","        directory = os.path.dirname(save_path)\n","        if directory:\n","            os.makedirs(directory, exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","    else:\n","        plt.show()                                                                                      # Exibe o gr√°fico"],"metadata":{"id":"ziF5r2tRrOEk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def visualizar_grade_latente(decodificador, tamanho_grade=20, save_path: Optional[str] = None):\n","    \"\"\"Gera uma grade de imagens decodificadas a partir de pontos regulares no espa√ßo latente 2D.\"\"\"\n","\n","    assert tamanho_grade > 1, \"Tamanho da grade deve ser maior que 1.\"   # Garante que a grade tenha pelo menos 2 pontos por eixo\n","\n","    # Gera coordenadas no espa√ßo latente com base nos percentis da Normal padr√£o N(0,1)\n","    # Usar percentis evita pontos extremos (muito afastados da densidade central)\n","    eixo = norm.ppf(np.linspace(0.01, 0.99, tamanho_grade))\n","\n","    linhas_imagem = []                                                   # Lista para armazenar linhas da grade de imagens\n","    for valor_y in eixo:                                                 # Varre o eixo vertical (dimens√£o z[1])\n","        linha_atual = []                                                 # Armazena as imagens de uma linha da grade\n","        for valor_x in eixo:                                             # Varre o eixo horizontal (dimens√£o z[0])\n","            # Cria o vetor latente z = [valor_x, valor_y]\n","            ponto_latente = torch.tensor([[valor_x, valor_y]], dtype=torch.float32, device=DISPOSITIVO)\n","            # Decodifica o ponto latente em uma imagem (sem gradientes)\n","            with torch.no_grad():\n","                imagem = decodificador(ponto_latente).cpu().squeeze().numpy()\n","            linha_atual.append(imagem)                                   # Adiciona imagem √† linha atual\n","        # Concatena horizontalmente as imagens da linha\n","        linhas_imagem.append(np.concatenate(linha_atual, axis=1))\n","\n","    # Concatena todas as linhas verticalmente -> imagem completa da grade\n","    imagem_grade = np.concatenate(linhas_imagem, axis=0)\n","\n","    fig = plt.figure(figsize=(8, 8))                                           # Define tamanho da figura\n","    plt.imshow(imagem_grade, cmap=\"binary\")                              # Exibe imagem composta em escala de cinza\n","    plt.axis(\"off\")                                                      # Remove eixos para visualiza√ß√£o limpa\n","    plt.title(\"Reconstru√ß√µes em grade no espa√ßo latente 2D\")             # T√≠tulo do gr√°fico\n","    plt.tight_layout()                                                   # Ajusta margens automaticamente\n","    if save_path:\n","        directory = os.path.dirname(save_path)\n","        if directory:\n","            os.makedirs(directory, exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","    else:\n","        plt.show()                                                                                      # Exibe o gr√°fico"],"metadata":{"id":"tBzFjUL0qe5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pcm0Z95uXyeV"},"outputs":[],"source":["def gerar_amostras_aleatorias(modelo, dimensao_latente, total_imagens, colunas, save_path: str):\n","    \"\"\"Gera novas amostras a partir de vetores latentes aleat√≥rios (z ~ N(0,1)).\"\"\"\n","\n","    modelo.eval()                                                                           # Coloca o modelo em modo de avalia√ß√£o\n","    with torch.no_grad():                                                                   # Desativa o c√°lculo de gradientes\n","        vetores_latentes = torch.randn(total_imagens, dimensao_latente, device=DISPOSITIVO) # Gera vetores latentes amostrados da distribui√ß√£o padr√£o N(0,1)\n","        imagens = modelo.decodificador(vetores_latentes).cpu().numpy()                      # Decodifica os vetores latentes em imagens sint√©ticas\n","\n","    linhas = (total_imagens - 1) // colunas + 1             # Calcula o n√∫mero de linhas necess√°rias para organizar as imagens na grade\n","    fig = plt.figure(figsize=(colunas, linhas))                   # Define tamanho proporcional da figura\n","\n","    # Exibe cada imagem na grade (linhas x colunas)\n","    for indice, imagem in enumerate(imagens):\n","        plt.subplot(linhas, colunas, indice + 1)            # Define posi√ß√£o do subplot\n","        plt.imshow(imagem.squeeze(), cmap=\"binary\")         # Exibe imagem (remove canal e usa tons de cinza)\n","        plt.axis(\"off\")                                     # Remove eixos para visualiza√ß√£o limpa\n","    plt.tight_layout()                                      # Ajusta margens automaticamente\n","    if save_path:\n","        directory = os.path.dirname(save_path)\n","        if directory:\n","            os.makedirs(directory, exist_ok=True)\n","        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n","        plt.close(fig)\n","    else:\n","        plt.show()                                                                                      # Exibe o gr√°fico"]},{"cell_type":"code","source":["def salvar_sumario_arquitetura(model, input_size, save_path: str):\n","    # Guarda o resultado do summary do torchinfo\n","    summary_stats = summary(model, input_size=input_size, col_names=(\"input_size\", \"output_size\", \"num_params\"), verbose=0)\n","\n","    # Converte para string.\n","    summary_text = str(summary_stats)\n","\n","    # Cria uma figura do Matplotlib para desenhar o texto\n","    fig = plt.figure(figsize=(12, 8))\n","    ax = fig.add_subplot(111)\n","    ax.axis('off')\n","\n","    # Adiciona o texto √† figura\n","    fig.text(0.05, 0.95, summary_text, transform=fig.transFigure,\n","             ha=\"left\", va=\"top\", fontfamily='monospace', fontsize=8)\n","\n","    directory = os.path.dirname(save_path)\n","    if directory:\n","        os.makedirs(directory, exist_ok=True)\n","\n","    # Salva em PDF\n","    fig.savefig(save_path, format='pdf', bbox_inches='tight')\n","    plt.close(fig)\n","    print(f\"Sum√°rio do modelo salvo em: {save_path}\")"],"metadata":{"id":"zlo_oG7vrzcz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Experimento"],"metadata":{"id":"I2F3WkH04Yug"}},{"cell_type":"code","source":["def executar_e_plotar_experimento(\n","    nome_experimento: str,\n","    model: nn.Module,\n","    output_dir: str,\n","    beta: float,\n","):\n","\n","    print(f\"\\n==============================================\")\n","    print(f\"  Executando: {nome_experimento}\")\n","    print(f\"==============================================\\n\")\n","\n","    otimizador_conv = torch.optim.Adam(model.parameters(), lr=1e-3)\n","    hist_loss, hist_mse, hist_kl = treinar_vae(\n","        modelo=model,\n","        carregador_treino=train_dl,\n","        epocas=EPOCAS_CONV,\n","        otimizador=otimizador_conv,\n","        beta=beta,\n","        nome_tag=nome_experimento,\n","    )\n","\n","    curvas_de_treinamento(hist_loss, hist_mse, hist_kl,\n","                          save_path=f\"{output_dir}/{nome_experimento}_curvas.pdf\")\n","\n","    mostrar_reconstrucoes(\n","        modelo=model,\n","        carregador_teste=test_dl,\n","        quantidade_imagens=10,\n","        save_path=f\"{output_dir}/{nome_experimento}_reconstrucoes.pdf\",\n","    )\n","\n","    visualizar_espaco_latente(\n","        modelo=model,\n","        carregador_dados=test_dl,\n","        save_path=f\"{output_dir}/{nome_experimento}_espaco_latente.pdf\",\n","    )\n","\n","    visualizar_grade_latente(\n","        decodificador=model.decodificador,\n","        tamanho_grade=25,\n","        save_path=f\"{output_dir}/{nome_experimento}_grade_latente.pdf\",\n","    )\n","\n","    gerar_amostras_aleatorias(\n","        modelo=model,\n","        dimensao_latente=DIMENSAO_LATENTE_CONV,\n","        total_imagens=50,\n","        colunas=10,\n","        save_path=f\"{output_dir}/{nome_experimento}_amostras.pdf\",\n","    )\n","\n"],"metadata":{"id":"9z6Oxmkj4Z9O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VWsI-i0kXyeW"},"source":["# Tarefa\n","\n","- Conjunto de dados a ser utilizado MNIST (ao inv√©s do Fashion MNIST):\n","\n","    ``` python\n","    train_data  = datasets.MNIST(root=\"data\", train=True, download=True)     # carrega conjunto de treinamento\n","    test_data   = datasets.MNIST(root=\"data\", train=False, download=True)    # carrega conjunto de teste\n","    ```\n","\n","1. Implemente uma vers√£o convolucional do VAE.\n","2. Treine a vers√£o convolucional do VAE com os valores diferentes para o par√¢metro $\\beta$ (ex.: $\\beta=\\in\\{0, 0.1, 100\\}$).\n","    - Mostre o termo de reconstru√ß√£o (MSE), o termo de regulariza√ß√£o (KL) e a fun√ß√£o de perda por √©poca (usando `curvas_de_treinamento`).\n","    - Mostre as reconstru√ß√µes (usando `mostrar_reconstrucoes`)\n","    - Mostre o espa√ßo latente (usando visualizar_espaco_latente e `visualizar_grade_latente`)\n","    - Gere amostras sint√©ticas (usando `gerar_amostras_aleatorias`)\n","\n","**Entreg√°veis**:\n","1. Notebook `.ipynb`.\n","2. Relat√≥rio `.pdf`:\n","    - Reporte e comente os resultados no relat√≥rio.\n","    - Incluir gr√°ficos gerados."]},{"cell_type":"code","source":["    vae_convolucional = AutoencoderVariacional(\n","        CodificadorConvolucional(DIMENSAO_LATENTE_CONV),\n","        DecodificadorConvolucional(DIMENSAO_LATENTE_CONV),\n","    ).to(DISPOSITIVO)\n","\n","    salvar_sumario_arquitetura(\n","        vae_convolucional,\n","        input_size=(1, 1, 28, 28),\n","        save_path=os.path.join(output_dir, f\"conv_vae_arquitetura.pdf\"),\n","    )\n","\n"],"metadata":{"id":"BB48FLiIAyUk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for b in {0, 0.1, 100}:\n","    executar_e_plotar_experimento(\n","        nome_experimento=f\"conv_vae_beta_{b}\",\n","        model=vae_convolucional,\n","        output_dir=output_dir,\n","        beta=b\n","    )\n"],"metadata":{"id":"nlhemmD34N0t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!zip -r /content/resultados_plots.zip /content/resultados_plots"],"metadata":{"id":"fJBCvUC78DFp"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1tRWTA_g1_nEg3mbmfhrkUKOCgaIy0nKa","timestamp":1760560665626}],"collapsed_sections":["9af74Nwj3BIy"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"}},"nbformat":4,"nbformat_minor":0}