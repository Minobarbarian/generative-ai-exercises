{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["7IlJowSa4Y6t","hSA-uH9HnDwG","DE4-1OsT5tgG","YCHFrGv3ea1H","u3mHuYgV5d1H","tIkdAq00PdGu","EyUvfr3U8lxx","DrU3JFj6Vyvc","gdOgx3jSNzFS","VBGGWyCBjClX"],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyN3gyFNTaLNC/crWTANPIrg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# IMD1114 - IA Generativa"],"metadata":{"id":"7IlJowSa4Y6t"}},{"cell_type":"markdown","source":["### Professor: Dr. Leonardo Enzo Brito da Silva"],"metadata":{"id":"M5edkneO4dGw"}},{"cell_type":"markdown","source":["### Aluno: João Antonio Costa Paiva Chagas"],"metadata":{"id":"nYOnHe-yZvEi"}},{"cell_type":"markdown","source":["# Tarefa:\n","\n","1. Implementar uma WCGAN condicional e treinar o modelo com o conjunto de dados Fashion MNIST.\n","\n","    a. Mostre os gráficos das funções de perda do gerador e do discriminador.\n","\n","    b. Mostre imagens geradas com o modelo.\n","\n","2. Interpolar entre vetores de ruído e mostrar as imagens intermediárias considerando:\n","\n","    a. z fixo e interpolacão linear entre classes [c1, c2].\n","\n","    b. classe c fixa e interpolaćão linear entre [z1, z2].\n","\n","    c. interpolaćão linear entre [z1, z2] e [c1, c2].\n","\n","3. Fixe o vetor de ruído e altere apenas o rótulo para observar como a imagem muda.\n","\n","**Entregáveis**:\n","1. Notebook `.ipynb`.\n","2. Relatório `.pdf`:\n","\n","    - Reporte e comente os resultados no relatório.\n","\n","    - Incluir imagens geradas."],"metadata":{"id":"SR7T2IbYZmsM"}},{"cell_type":"markdown","source":["### Importações:"],"metadata":{"id":"hSA-uH9HnDwG"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","from google.colab import drive"],"metadata":{"id":"_m30AxTg6l18"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ambiente:"],"metadata":{"id":"NyvqaPRGSaH9"}},{"cell_type":"code","source":["if not os.path.exists('files'):\n","    os.makedirs('files')"],"metadata":{"id":"nJEAfvsISdp_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"id":"hP2oqht3elEC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Usando dispositivo: {device}\")"],"metadata":{"id":"se4fA1H8Qbhm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["FMNIST_LABELS = {\n","    0: \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n","    5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\"\n","}"],"metadata":{"id":"Ahhm9L2gVBkj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MNIST_LABELS = {\n","    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n","    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n","}"],"metadata":{"id":"9sqFmUTvwhIM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dados:"],"metadata":{"id":"DE4-1OsT5tgG"}},{"cell_type":"code","source":["def prepare_data(batch_size, dataset_choice='FMNIST'):\n","    \"\"\"Carrega o dataset escolhido e retorna um DataLoader.\"\"\"\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5,), (0.5,)) # Normaliza as imagens para o intervalo [-1, 1]\n","    ])\n","\n","    if dataset_choice == 'FMNIST':\n","        training_data = datasets.FashionMNIST(\n","            root=\"data\", train=True, download=True, transform=transform\n","        )\n","    elif dataset_choice == 'MNIST':\n","        training_data = datasets.MNIST(\n","            root=\"data\", train=True, download=True, transform=transform\n","        )\n","\n","    return DataLoader(\n","        training_data,\n","        batch_size=batch_size,\n","        shuffle=True,\n","        num_workers=0,\n","        pin_memory=True\n","    )\n"],"metadata":{"id":"BBm7zkEnVJEf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Plots:"],"metadata":{"id":"WJAl5QHoKNe4"}},{"cell_type":"code","source":["def plot_loss_history(loss_g, loss_c):\n","    \"\"\"Plota o histórico de perdas do Gerador e do Crítico.\"\"\"\n","    plt.figure(figsize=(10, 5))\n","    plt.title(\"Perda do Gerador e Crítico Durante o Treinamento\")\n","    plt.plot(loss_g, label=\"Gerador\")\n","    plt.plot(loss_c, label=\"Crítico\")\n","    plt.xlabel(\"Épocas\")\n","    plt.ylabel(\"Perda (Wasserstein Distance Estimate)\")\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()"],"metadata":{"id":"0SKAovsuVSSn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_image_grid(images, titles=None, n_cols=5, figsize=(12, 6)):\n","    \"\"\"\n","    Plota uma grade de imagens com títulos opcionais.\n","    Esta função substitui plot_multiple_images, plotar_imagens e outras.\n","    \"\"\"\n","    if not images:\n","        print(\"Nenhuma imagem para plotar.\")\n","        return\n","\n","    n_rows = (len(images) - 1) // n_cols + 1\n","    plt.figure(figsize=figsize)\n","\n","    for index, img in enumerate(images):\n","        plt.subplot(n_rows, n_cols, index + 1)\n","        plt.imshow(img.reshape(28, 28), cmap=\"gray\")\n","        plt.axis(\"off\")\n","        if titles and index < len(titles):\n","            plt.title(titles[index])\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"b3KvZEucVVm5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Checkpoint"],"metadata":{"id":"YCHFrGv3ea1H"}},{"cell_type":"code","source":["def save_checkpoint(epoch, generator, critic, opt_g, opt_c, path=\"/content/drive/MyDrive/gan_checkpoint.pth\"):\n","    \"\"\"Salva o estado do treinamento.\"\"\"\n","    print(f\"==> Salvando checkpoint da época {epoch}...\")\n","    checkpoint = {\n","        'epoch': epoch,\n","        'generator_state_dict': generator.state_dict(),\n","        'critic_state_dict': critic.state_dict(),\n","        'opt_g_state_dict': opt_g.state_dict(),\n","        'opt_c_state_dict': opt_c.state_dict(),\n","    }\n","    torch.save(checkpoint, path)\n","\n","def load_checkpoint(generator, critic, opt_g, opt_c, path=\"/content/drive/MyDrive/gan_checkpoint.pth\"):\n","    \"\"\"Carrega o estado do treinamento de um checkpoint.\"\"\"\n","    start_epoch = 1\n","    if os.path.exists(path):\n","        print(f\"==> Carregando checkpoint de '{path}'...\")\n","        checkpoint = torch.load(path)\n","        generator.load_state_dict(checkpoint['generator_state_dict'])\n","        critic.load_state_dict(checkpoint['critic_state_dict'])\n","        opt_g.load_state_dict(checkpoint['opt_g_state_dict'])\n","        opt_c.load_state_dict(checkpoint['opt_c_state_dict'])\n","        start_epoch = checkpoint['epoch'] + 1\n","        print(f\"==> Checkpoint carregado. Reiniciando da época {start_epoch}\")\n","    else:\n","        print(\"==> Nenhum checkpoint encontrado. Iniciando do zero.\")\n","    return start_epoch"],"metadata":{"id":"-1uU2XxteeVp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### WGAN:"],"metadata":{"id":"B3zmdNza44fl"}},{"cell_type":"markdown","source":["#### Hiperparâmetros:"],"metadata":{"id":"3gPYkVnI5fRZ"}},{"cell_type":"code","source":["def get_hyperparameters():\n","    \"\"\"\n","    Retorna um dicionário de hiperparâmetros para o experimento WCGAN.\n","    \"\"\"\n","    return {\n","        'z_size': 100,\n","        'num_epochs': 25, # 50 para o gerador do lab 6, 25 para essa tarefa\n","        'batch_size': 64,\n","        'lr_g' : 0.0002,\n","        'lr_d' : 0.0002,\n","        'n_critic': 5,\n","        'lambda_gp': 10,\n","        'n_classes': 10,\n","        'embedding_dim': 10\n","    }"],"metadata":{"id":"ki7Rn1EpPC3h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Gerador:"],"metadata":{"id":"u3mHuYgV5d1H"}},{"cell_type":"code","source":["class Gerador(nn.Module):\n","    def __init__(self, z_dim, n_classes, embedding_dim):\n","        super().__init__()\n","        self.label_embedding = nn.Embedding(n_classes, embedding_dim)\n","        self.net = nn.Sequential(\n","            nn.Linear(z_dim + embedding_dim, 7*7*256), # 256 para o lab 6, 128 para esse lab\n","            nn.Unflatten(dim=1, unflattened_size=(256, 7, 7)),\n","            nn.BatchNorm2d(256),\n","            nn.ConvTranspose2d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1),\n","            nn.ReLU(True),\n","            nn.BatchNorm2d(128),\n","            nn.ConvTranspose2d(128, 1, kernel_size=5, stride=2, padding=2, output_padding=1),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, z, labels):\n","        c = self.label_embedding(labels)\n","        x = torch.cat([z, c], dim=1)\n","        return self.net(x)"],"metadata":{"id":"cpdFde48PQBG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Crítico:"],"metadata":{"id":"tIkdAq00PdGu"}},{"cell_type":"code","source":["class Critico(nn.Module):\n","    def __init__(self, n_classes, embedding_dim):\n","        super().__init__()\n","        self.label_embedding = nn.Embedding(n_classes, embedding_dim)\n","        self.conv_net = nn.Sequential(\n","            nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2),\n","            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2),\n","            nn.LeakyReLU(0.2),\n","            nn.Flatten(),\n","        )\n","        self.final_layer = nn.Linear(7*7*128 + embedding_dim, 1)\n","\n","    def forward(self, x, labels):\n","        conv_out = self.conv_net(x)\n","        c = self.label_embedding(labels)\n","        combined = torch.cat([conv_out, c], dim=1)\n","        return self.final_layer(combined)"],"metadata":{"id":"KM6E-qI7Pcxi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Treinamento:"],"metadata":{"id":"EyUvfr3U8lxx"}},{"cell_type":"code","source":["def compute_gradient_penalty(critic, real_samples, fake_samples, labels, device):\n","    \"\"\"Calculates the gradient penalty for a CONDITIONAL WGAN-GP.\"\"\"\n","    alpha = torch.rand(real_samples.size(0), 1, 1, 1, device=device)\n","    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n","\n","    critic_interpolates = critic(interpolates, labels)\n","\n","    gradients = torch.autograd.grad(\n","        outputs=critic_interpolates,\n","        inputs=interpolates,\n","        grad_outputs=torch.ones_like(critic_interpolates),\n","        create_graph=True,\n","        retain_graph=True,\n","    )[0]\n","\n","    gradients = gradients.view(gradients.size(0), -1)\n","    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n","    return gradient_penalty"],"metadata":{"id":"2r_GI9U3BNgY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_epoch(dataloader, generator, critic, opt_g, opt_c, params, epoch):\n","    \"\"\"Executa uma única época de treinamento para a WCGAN.\"\"\"\n","    generator.train()\n","    critic.train()\n","\n","    losses_c, losses_g = [], []\n","\n","    for real_data, labels in dataloader:\n","        batch_size = real_data.shape[0]\n","        real_data, labels = real_data.to(device), labels.to(device)\n","\n","        # --- Treinamento do Crítico ---\n","        for _ in range(params['n_critic']):\n","            z = torch.randn(batch_size, params['z_size'], device=device)\n","            fake_data = generator(z, labels).detach()\n","\n","            critic_real = critic(real_data, labels).mean()\n","            critic_fake = critic(fake_data, labels).mean()\n","            loss_c_original = critic_fake - critic_real\n","\n","            penalty = compute_gradient_penalty(critic, real_data, fake_data, labels, device)\n","\n","            loss_c = loss_c_original + params['lambda_gp'] * penalty\n","\n","            opt_c.zero_grad()\n","            loss_c.backward()\n","            opt_c.step()\n","\n","        losses_c.append(loss_c.item())\n","\n","        # --- Treinamento do Gerador ---\n","        z = torch.randn(batch_size, params['z_size'], device=device)\n","        fake_data = generator(z, labels)\n","        critic_fake_for_g = critic(fake_data, labels)\n","\n","        loss_g = -critic_fake_for_g.mean()\n","\n","        opt_g.zero_grad()\n","        loss_g.backward()\n","        opt_g.step()\n","\n","        losses_g.append(loss_g.item())\n","\n","    avg_loss_c = np.mean(losses_c)\n","    avg_loss_g = np.mean(losses_g)\n","    print(f\"[Época {epoch:02d}] Perda Média Crítico: {avg_loss_c:.4f} | Perda Média Gerador: {avg_loss_g:.4f}\")\n","\n","    return avg_loss_c, avg_loss_g"],"metadata":{"id":"zKcnQwJA5Mol"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def laco_de_treinamento(dataloader, generator, critic, params):\n","    \"\"\"Executa o loop de treinamento completo e retorna o histórico de perdas.\"\"\"\n","    history_c, history_g = [], []\n","\n","    optimizer_g = optim.Adam(generator.parameters(), lr=params['lr_g'], betas=(0.5, 0.9))\n","    optimizer_c = optim.Adam(critic.parameters(), lr=params['lr_d'], betas=(0.5, 0.9))\n","\n","    start_epoch = load_checkpoint(generator, critic, optimizer_g, optimizer_c)\n","\n","    print(\"Iniciando o treinamento da WCGAN...\")\n","    for epoch in range(start_epoch, params['num_epochs'] + 1):\n","        print(f\"epoch: {epoch}\")\n","        loss_c, loss_g = train_epoch(dataloader, generator, critic, optimizer_g, optimizer_c, params, epoch)\n","        history_c.append(loss_c)\n","        history_g.append(loss_g)\n","\n","        save_checkpoint(epoch, generator, critic, optimizer_g, optimizer_c)\n","\n","    print(\"\\nTreinamento concluído.\")\n","    return history_g, history_c"],"metadata":{"id":"1pu6TexTIZe-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Geração e Interpolação:"],"metadata":{"id":"DrU3JFj6Vyvc"}},{"cell_type":"code","source":["@torch.no_grad()\n","def generate_images_for_each_class(generator, z_dim, n_classes=10):\n","    \"\"\"Gera uma imagem para cada classe usando o mesmo vetor de ruído.\"\"\"\n","    generator.eval()\n","    z = torch.randn(1, z_dim, device=device).repeat(n_classes, 1)\n","    labels = torch.arange(n_classes, device=device)\n","    fake_data = generator(z, labels).cpu().numpy()\n","    return [img for img in fake_data]"],"metadata":{"id":"4WXxUgVgV4Z9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def generate_with_fixed_noise(generator, z_dim, n_classes=10):\n","    \"\"\"Gera imagens para todas as classes a partir de um único vetor de ruído fixo.\"\"\"\n","    generator.eval()\n","    z_fixed = torch.randn(1, z_dim, device=device)\n","    labels = torch.arange(n_classes, device=device)\n","    return [generator(z_fixed, lbl.unsqueeze(0)).cpu().squeeze().numpy() for lbl in labels]"],"metadata":{"id":"XLtXSK7pV64V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def interpolate_noise(generator, z_dim, fixed_class, steps=10):\n","    \"\"\"Mantém a classe fixa e interpola entre dois vetores de ruído.\"\"\"\n","    generator.eval()\n","    z1, z2 = torch.randn(1, z_dim, device=device), torch.randn(1, z_dim, device=device)\n","    label = torch.tensor([fixed_class], device=device)\n","    images = []\n","    for alpha in torch.linspace(0, 1, steps):\n","        z_interp = (1 - alpha) * z1 + alpha * z2\n","        images.append(generator(z_interp, label).cpu().squeeze().numpy())"],"metadata":{"id":"oEziDT8qV-j7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def interpolate_classes(generator, z_dim, c1, c2, steps=10):\n","    \"\"\"Mantém o ruído fixo e interpola entre os embeddings de duas classes.\"\"\"\n","    generator.eval()\n","    z_fixed = torch.randn(1, z_dim, device=device)\n","    embed_c1 = generator.label_embedding(torch.tensor([c1], device=device))\n","    embed_c2 = generator.label_embedding(torch.tensor([c2], device=device))\n","    images = []\n","    for alpha in torch.linspace(0, 1, steps):\n","        embed_interp = (1 - alpha) * embed_c1 + alpha * embed_c2\n","        combined_input = torch.cat([z_fixed, embed_interp], dim=1)\n","        images.append(generator.net(combined_input).cpu().squeeze().numpy())\n","    return images"],"metadata":{"id":"Lq5MWh_-WA1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad()\n","def interpolate_both(generator, z_dim, c1, c2, steps=10):\n","    \"\"\"Interpola simultaneamente entre dois vetores de ruído e duas classes.\"\"\"\n","    generator.eval()\n","    z1, z2 = torch.randn(1, z_dim, device=device), torch.randn(1, z_dim, device=device)\n","    label1, label2 = torch.tensor([c1], device=device), torch.tensor([c2], device=device)\n","    embed_c1 = generator.label_embedding(label1)\n","    embed_c2 = generator.label_embedding(label2)\n","    images = []\n","    for alpha in torch.linspace(0, 1, steps):\n","        z_interp = (1 - alpha) * z1 + alpha * z2\n","        embed_interp = (1 - alpha) * embed_c1 + alpha * embed_c2\n","        combined_input = torch.cat([z_interp, embed_interp], dim=1)\n","        images.append(generator.net(combined_input).cpu().squeeze().numpy())\n","    return images"],"metadata":{"id":"ZtsI0U6RWDW4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Salvando e carregando:"],"metadata":{"id":"gdOgx3jSNzFS"}},{"cell_type":"code","source":["def save_model(model, name, dataset_choice):\n","    \"\"\"Salva o modelo do gerador treinado num arquivo.\"\"\"\n","    model_path = f'files/{dataset_choice}_{name}_conv_wgan.pt'\n","    torch.jit.script(model).save(model_path)\n","    print(f\"\\nModelo final salvo em: {model_path}\")\n","    return model_path"],"metadata":{"id":"xwSBNTTp4dsr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_model(model_path, device):\n","    \"\"\"Carrega um modelo salvo e o configura para o modo de avaliação.\"\"\"\n","    loaded_model = torch.jit.load(model_path, map_location=device)\n","    loaded_model.eval()\n","    return loaded_model"],"metadata":{"id":"K-nAROF5tDU7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Executando:"],"metadata":{"id":"BnrrwLHmQhr1"}},{"cell_type":"code","source":["# --- Hiperparâmetros ---\n","params = get_hyperparameters()\n","\n","# --- Preparar Dados e Modelos ---\n","train_loader = prepare_data(params['batch_size'], 'FMNIST')\n","modelo_gerador = Gerador(params['z_size'], params['n_classes'], params['embedding_dim']).to(device)\n","modelo_critico = Critico(params['n_classes'], params['embedding_dim']).to(device)\n","\n","# --- Treinamento ---\n","loss_g_hist, loss_c_hist = laco_de_treinamento(train_loader, modelo_gerador, modelo_critico, params)\n","save_model(modelo_gerador, 'conditional', 'fmnist')"],"metadata":{"id":"mf-uEOhhWW93"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1a:"],"metadata":{"id":"FyOJO9CFWylE"}},{"cell_type":"code","source":["## Tarefa 1a: Gráficos das funções de perda\n","print(\"\\n--- Tarefa 1a: Gráfico de Perdas ---\")\n","plot_loss_history(loss_g_hist, loss_c_hist)"],"metadata":{"id":"cZZSJxP2W7Wb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1b:"],"metadata":{"id":"l5LpoGeCW0eh"}},{"cell_type":"code","source":["## Tarefa 1b: Imagens geradas com o modelo\n","print(\"\\n--- Tarefa 1b: Imagens Geradas (uma para cada classe) ---\")\n","imagens_por_classe = generate_images_for_each_class(modelo_gerador, params['z_size'])\n","titulos = [FMNIST_LABELS[i] for i in range(len(imagens_por_classe))]\n","plot_image_grid(imagens_por_classe, titles=titulos, n_cols=5, figsize=(12, 6))"],"metadata":{"id":"wr9qa7cSW9aC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2a:"],"metadata":{"id":"MpCeGYrAW2k7"}},{"cell_type":"code","source":["## Tarefa 2a: Interpolação entre classes (z fixo)\n","print(\"\\n--- Tarefa 2a: Interpolação entre Classes ---\")\n","c1, c2 = 5, 9  # Sandal -> Ankle Boot\n","imagens_interp_c = interpolate_classes(modelo_gerador, params['z_size'], c1, c2, steps=10)\n","print(f\"Interpolação: {FMNIST_LABELS[c1]} -> {FMNIST_LABELS[c2]}\")\n","plot_image_grid(imagens_interp_c, n_cols=10, figsize=(10, 2))"],"metadata":{"id":"ueG2OttlW_Dm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2b:"],"metadata":{"id":"og-fnfOoW3c0"}},{"cell_type":"code","source":["## Tarefa 2b: Interpolação entre vetores de ruído (c fixo)\n","print(\"\\n--- Tarefa 2b: Interpolação de Ruído ---\")\n","c_fixa = 8 # Bag\n","imagens_interp_z = interpolate_noise(modelo_gerador, params['z_size'], c_fixa, steps=10)\n","print(f\"Interpolação de ruído para a classe: {FMNIST_LABELS[c_fixa]}\")\n","plot_image_grid(imagens_interp_z, n_cols=10, figsize=(10, 2))"],"metadata":{"id":"ip5TpNpTXAWe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2c:"],"metadata":{"id":"ONsQnc3EW4E6"}},{"cell_type":"code","source":["## Tarefa 2c: Interpolação de ruído e classes\n","print(\"\\n--- Tarefa 2c: Interpolação de Ruído e Classes ---\")\n","c1, c2 = 1, 7 # Trouser -> Sneaker\n","imagens_interp_total = interpolate_both(modelo_gerador, params['z_size'], c1, c2, steps=10)\n","print(f\"Interpolação: {FMNIST_LABELS[c1]} -> {FMNIST_LABELS[c2]}\")\n","plot_image_grid(imagens_interp_total, n_cols=10, figsize=(10, 2))"],"metadata":{"id":"B_eYpOflXBmJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3:"],"metadata":{"id":"kdKMSVCNW5CV"}},{"cell_type":"code","source":["## Tarefa 3: Vetor de ruído fixo e alteração do rótulo\n","print(\"\\n--- Tarefa 3: Ruído Fixo, Classes Variadas ---\")\n","imagens_ruido_fixo = generate_with_fixed_noise(modelo_gerador, params['z_size'])\n","titulos_ruido_fixo = [FMNIST_LABELS[i] for i in range(len(imagens_ruido_fixo))]\n","plot_image_grid(imagens_ruido_fixo, titles=titulos_ruido_fixo, n_cols=10, figsize=(15, 3))"],"metadata":{"id":"LpGaNFrgXDL6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Para o lab 6:"],"metadata":{"id":"VBGGWyCBjClX"}},{"cell_type":"code","source":["# --- Hiperparâmetros ---\n","params = get_hyperparameters()\n","\n","# --- Preparar Dados e Modelos ---\n","train_loader = prepare_data(params['batch_size'], 'MNIST')\n","modelo_gerador = Gerador(params['z_size'], params['n_classes'], params['embedding_dim']).to(device)\n","modelo_critico = Critico(params['n_classes'], params['embedding_dim']).to(device)\n","\n","# --- Treinamento ---\n","loss_g_hist, loss_c_hist = laco_de_treinamento(train_loader, modelo_gerador, modelo_critico, params)\n","save_model(modelo_gerador, 'conditional', 'mnist')"],"metadata":{"id":"wnPPNOX4ilQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_loss_history(loss_g_hist, loss_c_hist)"],"metadata":{"id":"ngD_EGZrwASL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["imagens_por_classe = generate_images_for_each_class(modelo_gerador, params['z_size'])\n","titulos = [MNIST_LABELS[i] for i in range(len(imagens_por_classe))]\n","plot_image_grid(imagens_por_classe, titles=titulos, n_cols=5, figsize=(12, 6))"],"metadata":{"id":"1-ScvctJv5h9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# print"],"metadata":{"id":"5ypD_MBSUrvi"}},{"cell_type":"code","source":["!pip uninstall -y torchsummary\n","!pip install torch-summary"],"metadata":{"id":"pfx8tr34Zcbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchsummary import summary\n","params = get_hyperparameters()\n","\n","modelo_gerador = Gerador(params['z_size'], params['n_classes'], params['embedding_dim']).to(device)\n","modelo_critico = Critico(params['n_classes'], params['embedding_dim']).to(device)\n","\n","print(\"--- Generator Summary ---\")\n","summary(\n","    modelo_gerador,\n","    input_size=[(params['z_size'],), (1,)],\n","    dtypes=[torch.FloatTensor, torch.LongTensor],\n","    device=device,\n","    verbose=2\n",")\n","\n","print(\"\\n\" + \"=\"*60 + \"\\n\")\n","\n","print(\"--- Critic Summary ---\")\n","summary(\n","    modelo_critico,\n","    input_size=[(1, 28, 28), (1,)],\n","    dtypes=[torch.FloatTensor, torch.LongTensor],\n","    device=device,\n","    verbose=2\n",")"],"metadata":{"id":"ZGTFgajcUsrg"},"execution_count":null,"outputs":[]}]}